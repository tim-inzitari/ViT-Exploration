{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/tinzitar/anaconda3/envs/tf/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Requirement already satisfied: tensorflow-addons in /home/tinzitar/anaconda3/envs/tf/lib/python3.9/site-packages (0.17.1)\n",
      "Requirement already satisfied: typeguard>=2.7 in /home/tinzitar/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorflow-addons) (2.13.3)\n",
      "Requirement already satisfied: packaging in /home/tinzitar/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorflow-addons) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/tinzitar/anaconda3/envs/tf/lib/python3.9/site-packages (from packaging->tensorflow-addons) (3.0.9)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U tensorflow-addons\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_addons as tfa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3) - y_train shape: (50000, 1)\n",
      "x_test shape: (10000, 32, 32, 3) - y_test shape: (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "num_classes = 100\n",
    "input_shape = (32, 32, 3)\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar100.load_data()\n",
    "\n",
    "print(f\"x_train shape: {x_train.shape} - y_train shape: {y_train.shape}\")\n",
    "print(f\"x_test shape: {x_test.shape} - y_test shape: {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "weight_decay = 0.0001\n",
    "batch_size = 256\n",
    "num_epochs = 100\n",
    "image_size = 72  # image size after resize\n",
    "patch_size = 16  # Size of the patches\n",
    "num_patches = (image_size // patch_size) ** 2\n",
    "projection_dim = 64\n",
    "num_heads = 4\n",
    "transformer_units = [projection_dim * 2, projection_dim,]  # Size of the transformer layers\n",
    "transformer_layers = 4\n",
    "mlp_head_units = [2048, 1024]  # Size of the dense layers of the final classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-29 18:41:37.354321: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-29 18:41:38.045501: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 11194 MB memory:  -> device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:03:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "data_augment = keras.Sequential(\n",
    "    [\n",
    "        layers.Normalization(),\n",
    "        layers.Resizing(image_size, image_size),\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(factor=0.02),\n",
    "        layers.RandomZoom(\n",
    "            height_factor=0.2, width_factor=0.2\n",
    "        ),\n",
    "    ],\n",
    "    name=\"data_augment\",\n",
    ")\n",
    "# Compute the mean and the variance of the training data for normalization.\n",
    "data_augment.layers[0].adapt(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(x, hidden_units, dropout_rate):\n",
    "    for units in hidden_units:\n",
    "        x = layers.Dense(units, activation=tf.nn.gelu)(x)\n",
    "        x = layers.Dropout(dropout_rate)(x)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Patches(layers.Layer):\n",
    "    def __init__(self, patch_size):\n",
    "        super(Patches, self).__init__()\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "    def call(self, images):\n",
    "        batch_size = tf.shape(images)[0]\n",
    "        patches = tf.image.extract_patches(\n",
    "            images=images,\n",
    "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
    "            strides=[1, self.patch_size, self.patch_size, 1],\n",
    "            rates=[1, 1, 1, 1],\n",
    "            padding=\"VALID\",\n",
    "        )\n",
    "        patch_dims = patches.shape[-1]\n",
    "        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n",
    "        return patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image size: 72 X 72\n",
      "Patch size: 16 X 16\n",
      "Patches per image: 16\n",
      "Elements per patch: 768\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "image = x_train[np.random.choice(range(x_train.shape[0]))]\n",
    "plt.imshow(image.astype(\"uint8\"))\n",
    "plt.axis(\"off\")\n",
    "\n",
    "resized_image = tf.image.resize(\n",
    "    tf.convert_to_tensor([image]), size=(image_size, image_size)\n",
    ")\n",
    "patches = Patches(patch_size)(resized_image)\n",
    "print(f\"Image size: {image_size} X {image_size}\")\n",
    "print(f\"Patch size: {patch_size} X {patch_size}\")\n",
    "print(f\"Patches per image: {patches.shape[1]}\")\n",
    "print(f\"Elements per patch: {patches.shape[-1]}\")\n",
    "\n",
    "n = int(np.sqrt(patches.shape[1]))\n",
    "plt.figure(figsize=(4, 4))\n",
    "for i, patch in enumerate(patches[0]):\n",
    "    ax = plt.subplot(n, n, i + 1)\n",
    "    patch_img = tf.reshape(patch, (patch_size, patch_size, 3))\n",
    "    plt.imshow(patch_img.numpy().astype(\"uint8\"))\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchEncoder(layers.Layer):\n",
    "    def __init__(self, num_patches, projection_dim):\n",
    "        super(PatchEncoder, self).__init__()\n",
    "        self.num_patches = num_patches\n",
    "        self.projection = layers.Dense(units=projection_dim)\n",
    "        self.position_embedding = layers.Embedding(\n",
    "            input_dim=num_patches, output_dim=projection_dim\n",
    "        )\n",
    "\n",
    "    def call(self, patch):\n",
    "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
    "        encoded = self.projection(patch) + self.position_embedding(positions)\n",
    "        return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vit_classifier():\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    # Augment data.\n",
    "    augmented = data_augment(inputs)\n",
    "    # Create patches.\n",
    "    patches = Patches(patch_size)(augmented)\n",
    "    # Encode patches.\n",
    "    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n",
    "\n",
    "    # Create multiple layers of the Transformer block.\n",
    "    for _ in range(transformer_layers):\n",
    "        # Layer normalization 1.\n",
    "        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "        # Create a multi-head attention layer.\n",
    "        attention_output = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n",
    "        )(x1, x1)\n",
    "        # Skip connection 1.\n",
    "        x2 = layers.Add()([attention_output, encoded_patches])\n",
    "        # Layer normalization 2.\n",
    "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "        # MLP.\n",
    "        x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1)\n",
    "        # Skip connection 2.\n",
    "        encoded_patches = layers.Add()([x3, x2])\n",
    "\n",
    "    # Create a [batch_size, projection_dim] tensor.\n",
    "    representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "    representation = layers.Flatten()(representation)\n",
    "    representation = layers.Dropout(0.5)(representation)\n",
    "    # Add MLP.\n",
    "    features = mlp(representation, hidden_units=mlp_head_units, dropout_rate=0.5)\n",
    "    # Classify outputs.\n",
    "    logits = layers.Dense(num_classes)(features)\n",
    "    # Create the Keras model.\n",
    "    model = keras.Model(inputs=inputs, outputs=logits)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "4 layers\n",
      "------------------\n",
      "Epoch 1/100\n",
      "176/176 [==============================] - 31s 133ms/step - loss: 4.2483 - accuracy: 0.0689 - top-5-accuracy: 0.2168 - val_loss: 3.6644 - val_accuracy: 0.1350 - val_top-5-accuracy: 0.3732\n",
      "Epoch 2/100\n",
      "176/176 [==============================] - 22s 127ms/step - loss: 3.7758 - accuracy: 0.1232 - top-5-accuracy: 0.3454 - val_loss: 3.4713 - val_accuracy: 0.1746 - val_top-5-accuracy: 0.4314\n",
      "Epoch 3/100\n",
      "176/176 [==============================] - 22s 125ms/step - loss: 3.5682 - accuracy: 0.1550 - top-5-accuracy: 0.4050 - val_loss: 3.2932 - val_accuracy: 0.2074 - val_top-5-accuracy: 0.4748\n",
      "Epoch 4/100\n",
      "176/176 [==============================] - 22s 127ms/step - loss: 3.4293 - accuracy: 0.1810 - top-5-accuracy: 0.4451 - val_loss: 3.1847 - val_accuracy: 0.2256 - val_top-5-accuracy: 0.5062\n",
      "Epoch 5/100\n",
      "176/176 [==============================] - 22s 126ms/step - loss: 3.3311 - accuracy: 0.1987 - top-5-accuracy: 0.4714 - val_loss: 3.0708 - val_accuracy: 0.2454 - val_top-5-accuracy: 0.5416\n",
      "Epoch 6/100\n",
      "176/176 [==============================] - 23s 128ms/step - loss: 3.2350 - accuracy: 0.2120 - top-5-accuracy: 0.4968 - val_loss: 3.0079 - val_accuracy: 0.2636 - val_top-5-accuracy: 0.5526\n",
      "Epoch 7/100\n",
      "176/176 [==============================] - 22s 127ms/step - loss: 3.1624 - accuracy: 0.2300 - top-5-accuracy: 0.5140 - val_loss: 2.9481 - val_accuracy: 0.2684 - val_top-5-accuracy: 0.5626\n",
      "Epoch 8/100\n",
      "176/176 [==============================] - 22s 125ms/step - loss: 3.0946 - accuracy: 0.2396 - top-5-accuracy: 0.5316 - val_loss: 2.8802 - val_accuracy: 0.2884 - val_top-5-accuracy: 0.5810\n",
      "Epoch 9/100\n",
      "176/176 [==============================] - 22s 127ms/step - loss: 3.0320 - accuracy: 0.2504 - top-5-accuracy: 0.5454 - val_loss: 2.8401 - val_accuracy: 0.2960 - val_top-5-accuracy: 0.5920\n",
      "Epoch 10/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 2.9913 - accuracy: 0.2585 - top-5-accuracy: 0.5564 - val_loss: 2.8154 - val_accuracy: 0.2938 - val_top-5-accuracy: 0.5926\n",
      "Epoch 11/100\n",
      "176/176 [==============================] - 23s 128ms/step - loss: 2.9426 - accuracy: 0.2695 - top-5-accuracy: 0.5675 - val_loss: 2.7613 - val_accuracy: 0.3112 - val_top-5-accuracy: 0.6080\n",
      "Epoch 12/100\n",
      "176/176 [==============================] - 22s 126ms/step - loss: 2.9010 - accuracy: 0.2776 - top-5-accuracy: 0.5812 - val_loss: 2.7493 - val_accuracy: 0.3134 - val_top-5-accuracy: 0.6112\n",
      "Epoch 13/100\n",
      "176/176 [==============================] - 22s 125ms/step - loss: 2.8573 - accuracy: 0.2842 - top-5-accuracy: 0.5873 - val_loss: 2.7005 - val_accuracy: 0.3218 - val_top-5-accuracy: 0.6200\n",
      "Epoch 14/100\n",
      "176/176 [==============================] - 22s 127ms/step - loss: 2.8234 - accuracy: 0.2898 - top-5-accuracy: 0.5970 - val_loss: 2.6647 - val_accuracy: 0.3300 - val_top-5-accuracy: 0.6258\n",
      "Epoch 15/100\n",
      "176/176 [==============================] - 21s 122ms/step - loss: 2.7941 - accuracy: 0.2935 - top-5-accuracy: 0.6052 - val_loss: 2.6707 - val_accuracy: 0.3298 - val_top-5-accuracy: 0.6276\n",
      "Epoch 16/100\n",
      "176/176 [==============================] - 22s 126ms/step - loss: 2.7560 - accuracy: 0.3038 - top-5-accuracy: 0.6134 - val_loss: 2.6256 - val_accuracy: 0.3414 - val_top-5-accuracy: 0.6338\n",
      "Epoch 17/100\n",
      "176/176 [==============================] - 22s 125ms/step - loss: 2.7268 - accuracy: 0.3088 - top-5-accuracy: 0.6192 - val_loss: 2.5764 - val_accuracy: 0.3464 - val_top-5-accuracy: 0.6410\n",
      "Epoch 18/100\n",
      "176/176 [==============================] - 22s 124ms/step - loss: 2.6953 - accuracy: 0.3160 - top-5-accuracy: 0.6296 - val_loss: 2.5885 - val_accuracy: 0.3484 - val_top-5-accuracy: 0.6468\n",
      "Epoch 19/100\n",
      "176/176 [==============================] - 22s 127ms/step - loss: 2.6614 - accuracy: 0.3239 - top-5-accuracy: 0.6362 - val_loss: 2.5462 - val_accuracy: 0.3592 - val_top-5-accuracy: 0.6566\n",
      "Epoch 20/100\n",
      "176/176 [==============================] - 22s 124ms/step - loss: 2.6313 - accuracy: 0.3271 - top-5-accuracy: 0.6441 - val_loss: 2.5333 - val_accuracy: 0.3538 - val_top-5-accuracy: 0.6552\n",
      "Epoch 21/100\n",
      "176/176 [==============================] - 22s 124ms/step - loss: 2.6070 - accuracy: 0.3348 - top-5-accuracy: 0.6476 - val_loss: 2.4966 - val_accuracy: 0.3676 - val_top-5-accuracy: 0.6672\n",
      "Epoch 22/100\n",
      "176/176 [==============================] - 22s 127ms/step - loss: 2.5762 - accuracy: 0.3398 - top-5-accuracy: 0.6557 - val_loss: 2.4861 - val_accuracy: 0.3728 - val_top-5-accuracy: 0.6722\n",
      "Epoch 23/100\n",
      "176/176 [==============================] - 22s 125ms/step - loss: 2.5629 - accuracy: 0.3397 - top-5-accuracy: 0.6590 - val_loss: 2.4621 - val_accuracy: 0.3784 - val_top-5-accuracy: 0.6688\n",
      "Epoch 24/100\n",
      "176/176 [==============================] - 21s 121ms/step - loss: 2.5353 - accuracy: 0.3500 - top-5-accuracy: 0.6610 - val_loss: 2.4619 - val_accuracy: 0.3728 - val_top-5-accuracy: 0.6696\n",
      "Epoch 25/100\n",
      "176/176 [==============================] - 22s 127ms/step - loss: 2.5161 - accuracy: 0.3494 - top-5-accuracy: 0.6697 - val_loss: 2.4315 - val_accuracy: 0.3820 - val_top-5-accuracy: 0.6764\n",
      "Epoch 26/100\n",
      "176/176 [==============================] - 22s 125ms/step - loss: 2.4987 - accuracy: 0.3548 - top-5-accuracy: 0.6721 - val_loss: 2.4488 - val_accuracy: 0.3864 - val_top-5-accuracy: 0.6722\n",
      "Epoch 27/100\n",
      "176/176 [==============================] - 22s 125ms/step - loss: 2.4887 - accuracy: 0.3560 - top-5-accuracy: 0.6743 - val_loss: 2.4257 - val_accuracy: 0.3836 - val_top-5-accuracy: 0.6744\n",
      "Epoch 28/100\n",
      "176/176 [==============================] - 22s 124ms/step - loss: 2.4656 - accuracy: 0.3616 - top-5-accuracy: 0.6802 - val_loss: 2.4020 - val_accuracy: 0.3862 - val_top-5-accuracy: 0.6770\n",
      "Epoch 29/100\n",
      "176/176 [==============================] - 22s 125ms/step - loss: 2.4403 - accuracy: 0.3637 - top-5-accuracy: 0.6852 - val_loss: 2.4098 - val_accuracy: 0.3848 - val_top-5-accuracy: 0.6826\n",
      "Epoch 30/100\n",
      "176/176 [==============================] - 22s 126ms/step - loss: 2.4146 - accuracy: 0.3703 - top-5-accuracy: 0.6918 - val_loss: 2.3805 - val_accuracy: 0.3914 - val_top-5-accuracy: 0.6864\n",
      "Epoch 31/100\n",
      "176/176 [==============================] - 22s 126ms/step - loss: 2.4138 - accuracy: 0.3732 - top-5-accuracy: 0.6911 - val_loss: 2.3662 - val_accuracy: 0.3990 - val_top-5-accuracy: 0.6878\n",
      "Epoch 32/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 2.3841 - accuracy: 0.3762 - top-5-accuracy: 0.6981 - val_loss: 2.3888 - val_accuracy: 0.3962 - val_top-5-accuracy: 0.6842\n",
      "Epoch 33/100\n",
      "176/176 [==============================] - 22s 124ms/step - loss: 2.3806 - accuracy: 0.3774 - top-5-accuracy: 0.6990 - val_loss: 2.3791 - val_accuracy: 0.3954 - val_top-5-accuracy: 0.6888\n",
      "Epoch 34/100\n",
      "176/176 [==============================] - 22s 126ms/step - loss: 2.3560 - accuracy: 0.3830 - top-5-accuracy: 0.7021 - val_loss: 2.3493 - val_accuracy: 0.4056 - val_top-5-accuracy: 0.6932\n",
      "Epoch 35/100\n",
      "176/176 [==============================] - 22s 125ms/step - loss: 2.3480 - accuracy: 0.3864 - top-5-accuracy: 0.7059 - val_loss: 2.3335 - val_accuracy: 0.4100 - val_top-5-accuracy: 0.6946\n",
      "Epoch 36/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 2.3284 - accuracy: 0.3886 - top-5-accuracy: 0.7098 - val_loss: 2.3176 - val_accuracy: 0.4060 - val_top-5-accuracy: 0.6984\n",
      "Epoch 37/100\n",
      "176/176 [==============================] - 22s 124ms/step - loss: 2.3150 - accuracy: 0.3927 - top-5-accuracy: 0.7117 - val_loss: 2.3263 - val_accuracy: 0.4104 - val_top-5-accuracy: 0.6940\n",
      "Epoch 38/100\n",
      "176/176 [==============================] - 22s 125ms/step - loss: 2.2975 - accuracy: 0.3980 - top-5-accuracy: 0.7165 - val_loss: 2.3078 - val_accuracy: 0.4158 - val_top-5-accuracy: 0.7002\n",
      "Epoch 39/100\n",
      "176/176 [==============================] - 22s 124ms/step - loss: 2.2969 - accuracy: 0.3960 - top-5-accuracy: 0.7169 - val_loss: 2.2995 - val_accuracy: 0.4166 - val_top-5-accuracy: 0.7012\n",
      "Epoch 40/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 2.2864 - accuracy: 0.3979 - top-5-accuracy: 0.7168 - val_loss: 2.2959 - val_accuracy: 0.4118 - val_top-5-accuracy: 0.7032\n",
      "Epoch 41/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 22s 124ms/step - loss: 2.2648 - accuracy: 0.4012 - top-5-accuracy: 0.7219 - val_loss: 2.3048 - val_accuracy: 0.4176 - val_top-5-accuracy: 0.6988\n",
      "Epoch 42/100\n",
      "176/176 [==============================] - 22s 125ms/step - loss: 2.2622 - accuracy: 0.4038 - top-5-accuracy: 0.7241 - val_loss: 2.2787 - val_accuracy: 0.4116 - val_top-5-accuracy: 0.7074\n",
      "Epoch 43/100\n",
      "176/176 [==============================] - 22s 125ms/step - loss: 2.2441 - accuracy: 0.4043 - top-5-accuracy: 0.7295 - val_loss: 2.2835 - val_accuracy: 0.4248 - val_top-5-accuracy: 0.7024\n",
      "Epoch 44/100\n",
      "176/176 [==============================] - 22s 124ms/step - loss: 2.2451 - accuracy: 0.4024 - top-5-accuracy: 0.7279 - val_loss: 2.2823 - val_accuracy: 0.4134 - val_top-5-accuracy: 0.7060\n",
      "Epoch 45/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 2.2232 - accuracy: 0.4110 - top-5-accuracy: 0.7310 - val_loss: 2.2948 - val_accuracy: 0.4136 - val_top-5-accuracy: 0.7018\n",
      "Epoch 46/100\n",
      "176/176 [==============================] - 22s 124ms/step - loss: 2.2168 - accuracy: 0.4112 - top-5-accuracy: 0.7320 - val_loss: 2.2646 - val_accuracy: 0.4246 - val_top-5-accuracy: 0.7094\n",
      "Epoch 47/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 2.2022 - accuracy: 0.4158 - top-5-accuracy: 0.7360 - val_loss: 2.2588 - val_accuracy: 0.4208 - val_top-5-accuracy: 0.7072\n",
      "Epoch 48/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 2.1958 - accuracy: 0.4169 - top-5-accuracy: 0.7374 - val_loss: 2.2518 - val_accuracy: 0.4238 - val_top-5-accuracy: 0.7112\n",
      "Epoch 49/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 2.1802 - accuracy: 0.4173 - top-5-accuracy: 0.7411 - val_loss: 2.2609 - val_accuracy: 0.4242 - val_top-5-accuracy: 0.7096\n",
      "Epoch 50/100\n",
      "176/176 [==============================] - 22s 124ms/step - loss: 2.1824 - accuracy: 0.4179 - top-5-accuracy: 0.7407 - val_loss: 2.2568 - val_accuracy: 0.4280 - val_top-5-accuracy: 0.7144\n",
      "Epoch 51/100\n",
      "176/176 [==============================] - 22s 125ms/step - loss: 2.1662 - accuracy: 0.4244 - top-5-accuracy: 0.7444 - val_loss: 2.2476 - val_accuracy: 0.4282 - val_top-5-accuracy: 0.7098\n",
      "Epoch 52/100\n",
      "176/176 [==============================] - 21s 122ms/step - loss: 2.1506 - accuracy: 0.4260 - top-5-accuracy: 0.7475 - val_loss: 2.2499 - val_accuracy: 0.4258 - val_top-5-accuracy: 0.7108\n",
      "Epoch 53/100\n",
      "176/176 [==============================] - 22s 125ms/step - loss: 2.1544 - accuracy: 0.4246 - top-5-accuracy: 0.7480 - val_loss: 2.2375 - val_accuracy: 0.4304 - val_top-5-accuracy: 0.7128\n",
      "Epoch 54/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 2.1396 - accuracy: 0.4285 - top-5-accuracy: 0.7490 - val_loss: 2.2468 - val_accuracy: 0.4246 - val_top-5-accuracy: 0.7112\n",
      "Epoch 55/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 2.1373 - accuracy: 0.4271 - top-5-accuracy: 0.7533 - val_loss: 2.2310 - val_accuracy: 0.4188 - val_top-5-accuracy: 0.7196\n",
      "Epoch 56/100\n",
      "176/176 [==============================] - 21s 122ms/step - loss: 2.1324 - accuracy: 0.4283 - top-5-accuracy: 0.7508 - val_loss: 2.2321 - val_accuracy: 0.4272 - val_top-5-accuracy: 0.7178\n",
      "Epoch 57/100\n",
      "176/176 [==============================] - 22s 125ms/step - loss: 2.1246 - accuracy: 0.4326 - top-5-accuracy: 0.7531 - val_loss: 2.2390 - val_accuracy: 0.4276 - val_top-5-accuracy: 0.7142\n",
      "Epoch 58/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 2.1194 - accuracy: 0.4322 - top-5-accuracy: 0.7508 - val_loss: 2.2330 - val_accuracy: 0.4286 - val_top-5-accuracy: 0.7164\n",
      "Epoch 59/100\n",
      "176/176 [==============================] - 22s 124ms/step - loss: 2.0998 - accuracy: 0.4380 - top-5-accuracy: 0.7599 - val_loss: 2.2348 - val_accuracy: 0.4266 - val_top-5-accuracy: 0.7126\n",
      "Epoch 60/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 2.0922 - accuracy: 0.4396 - top-5-accuracy: 0.7588 - val_loss: 2.2312 - val_accuracy: 0.4278 - val_top-5-accuracy: 0.7094\n",
      "Epoch 61/100\n",
      "176/176 [==============================] - 22s 126ms/step - loss: 2.0933 - accuracy: 0.4418 - top-5-accuracy: 0.7601 - val_loss: 2.2190 - val_accuracy: 0.4320 - val_top-5-accuracy: 0.7128\n",
      "Epoch 62/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 2.0862 - accuracy: 0.4387 - top-5-accuracy: 0.7619 - val_loss: 2.2212 - val_accuracy: 0.4282 - val_top-5-accuracy: 0.7130\n",
      "Epoch 63/100\n",
      "176/176 [==============================] - 22s 125ms/step - loss: 2.0734 - accuracy: 0.4412 - top-5-accuracy: 0.7637 - val_loss: 2.2094 - val_accuracy: 0.4354 - val_top-5-accuracy: 0.7146\n",
      "Epoch 64/100\n",
      "176/176 [==============================] - 22s 125ms/step - loss: 2.0682 - accuracy: 0.4476 - top-5-accuracy: 0.7646 - val_loss: 2.2180 - val_accuracy: 0.4364 - val_top-5-accuracy: 0.7198\n",
      "Epoch 65/100\n",
      "176/176 [==============================] - 22s 125ms/step - loss: 2.0699 - accuracy: 0.4439 - top-5-accuracy: 0.7642 - val_loss: 2.1903 - val_accuracy: 0.4386 - val_top-5-accuracy: 0.7218\n",
      "Epoch 66/100\n",
      "176/176 [==============================] - 22s 125ms/step - loss: 2.0450 - accuracy: 0.4469 - top-5-accuracy: 0.7703 - val_loss: 2.1809 - val_accuracy: 0.4402 - val_top-5-accuracy: 0.7182\n",
      "Epoch 67/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 2.0572 - accuracy: 0.4438 - top-5-accuracy: 0.7663 - val_loss: 2.1940 - val_accuracy: 0.4318 - val_top-5-accuracy: 0.7228\n",
      "Epoch 68/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 2.0391 - accuracy: 0.4502 - top-5-accuracy: 0.7736 - val_loss: 2.1988 - val_accuracy: 0.4334 - val_top-5-accuracy: 0.7258\n",
      "Epoch 69/100\n",
      "176/176 [==============================] - 22s 125ms/step - loss: 2.0340 - accuracy: 0.4514 - top-5-accuracy: 0.7692 - val_loss: 2.1632 - val_accuracy: 0.4450 - val_top-5-accuracy: 0.7282\n",
      "Epoch 70/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 2.0217 - accuracy: 0.4521 - top-5-accuracy: 0.7742 - val_loss: 2.1754 - val_accuracy: 0.4424 - val_top-5-accuracy: 0.7266\n",
      "Epoch 71/100\n",
      "176/176 [==============================] - 21s 122ms/step - loss: 2.0219 - accuracy: 0.4504 - top-5-accuracy: 0.7772 - val_loss: 2.1952 - val_accuracy: 0.4358 - val_top-5-accuracy: 0.7248\n",
      "Epoch 72/100\n",
      "176/176 [==============================] - 22s 126ms/step - loss: 2.0198 - accuracy: 0.4530 - top-5-accuracy: 0.7733 - val_loss: 2.1794 - val_accuracy: 0.4464 - val_top-5-accuracy: 0.7258\n",
      "Epoch 73/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 2.0135 - accuracy: 0.4542 - top-5-accuracy: 0.7753 - val_loss: 2.1681 - val_accuracy: 0.4412 - val_top-5-accuracy: 0.7278\n",
      "Epoch 74/100\n",
      "176/176 [==============================] - 22s 124ms/step - loss: 1.9997 - accuracy: 0.4595 - top-5-accuracy: 0.7772 - val_loss: 2.1824 - val_accuracy: 0.4360 - val_top-5-accuracy: 0.7212\n",
      "Epoch 75/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 1.9897 - accuracy: 0.4608 - top-5-accuracy: 0.7813 - val_loss: 2.1625 - val_accuracy: 0.4398 - val_top-5-accuracy: 0.7252\n",
      "Epoch 76/100\n",
      "176/176 [==============================] - 22s 124ms/step - loss: 2.0025 - accuracy: 0.4577 - top-5-accuracy: 0.7787 - val_loss: 2.1590 - val_accuracy: 0.4380 - val_top-5-accuracy: 0.7274\n",
      "Epoch 77/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 1.9849 - accuracy: 0.4621 - top-5-accuracy: 0.7833 - val_loss: 2.1534 - val_accuracy: 0.4438 - val_top-5-accuracy: 0.7330\n",
      "Epoch 78/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 1.9878 - accuracy: 0.4595 - top-5-accuracy: 0.7814 - val_loss: 2.1540 - val_accuracy: 0.4432 - val_top-5-accuracy: 0.7294\n",
      "Epoch 79/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 1.9780 - accuracy: 0.4632 - top-5-accuracy: 0.7835 - val_loss: 2.1518 - val_accuracy: 0.4392 - val_top-5-accuracy: 0.7304\n",
      "Epoch 80/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 1.9693 - accuracy: 0.4651 - top-5-accuracy: 0.7838 - val_loss: 2.1599 - val_accuracy: 0.4422 - val_top-5-accuracy: 0.7298\n",
      "Epoch 81/100\n",
      "176/176 [==============================] - 22s 125ms/step - loss: 1.9612 - accuracy: 0.4680 - top-5-accuracy: 0.7861 - val_loss: 2.1234 - val_accuracy: 0.4534 - val_top-5-accuracy: 0.7384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/100\n",
      "176/176 [==============================] - 22s 124ms/step - loss: 1.9522 - accuracy: 0.4690 - top-5-accuracy: 0.7884 - val_loss: 2.1290 - val_accuracy: 0.4540 - val_top-5-accuracy: 0.7362\n",
      "Epoch 83/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 1.9620 - accuracy: 0.4660 - top-5-accuracy: 0.7865 - val_loss: 2.1396 - val_accuracy: 0.4478 - val_top-5-accuracy: 0.7348\n",
      "Epoch 84/100\n",
      "176/176 [==============================] - 22s 124ms/step - loss: 1.9514 - accuracy: 0.4682 - top-5-accuracy: 0.7892 - val_loss: 2.1356 - val_accuracy: 0.4560 - val_top-5-accuracy: 0.7326\n",
      "Epoch 85/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 1.9457 - accuracy: 0.4697 - top-5-accuracy: 0.7912 - val_loss: 2.1387 - val_accuracy: 0.4508 - val_top-5-accuracy: 0.7346\n",
      "Epoch 86/100\n",
      "176/176 [==============================] - 21s 122ms/step - loss: 1.9470 - accuracy: 0.4668 - top-5-accuracy: 0.7888 - val_loss: 2.1163 - val_accuracy: 0.4520 - val_top-5-accuracy: 0.7412\n",
      "Epoch 87/100\n",
      "176/176 [==============================] - 22s 126ms/step - loss: 1.9405 - accuracy: 0.4708 - top-5-accuracy: 0.7902 - val_loss: 2.1165 - val_accuracy: 0.4570 - val_top-5-accuracy: 0.7380\n",
      "Epoch 88/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 1.9276 - accuracy: 0.4743 - top-5-accuracy: 0.7922 - val_loss: 2.1267 - val_accuracy: 0.4556 - val_top-5-accuracy: 0.7388\n",
      "Epoch 89/100\n",
      "176/176 [==============================] - 22s 124ms/step - loss: 1.9163 - accuracy: 0.4737 - top-5-accuracy: 0.7957 - val_loss: 2.1246 - val_accuracy: 0.4500 - val_top-5-accuracy: 0.7346\n",
      "Epoch 90/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 1.9259 - accuracy: 0.4733 - top-5-accuracy: 0.7933 - val_loss: 2.0927 - val_accuracy: 0.4592 - val_top-5-accuracy: 0.7442\n",
      "Epoch 91/100\n",
      "176/176 [==============================] - 22s 124ms/step - loss: 1.9136 - accuracy: 0.4764 - top-5-accuracy: 0.7952 - val_loss: 2.1150 - val_accuracy: 0.4554 - val_top-5-accuracy: 0.7420\n",
      "Epoch 92/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 1.9167 - accuracy: 0.4774 - top-5-accuracy: 0.7937 - val_loss: 2.1124 - val_accuracy: 0.4544 - val_top-5-accuracy: 0.7404\n",
      "Epoch 93/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 1.9042 - accuracy: 0.4776 - top-5-accuracy: 0.7976 - val_loss: 2.1384 - val_accuracy: 0.4550 - val_top-5-accuracy: 0.7320\n",
      "Epoch 94/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 1.9121 - accuracy: 0.4781 - top-5-accuracy: 0.7970 - val_loss: 2.1163 - val_accuracy: 0.4548 - val_top-5-accuracy: 0.7416\n",
      "Epoch 95/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 1.9009 - accuracy: 0.4809 - top-5-accuracy: 0.7999 - val_loss: 2.1172 - val_accuracy: 0.4554 - val_top-5-accuracy: 0.7362\n",
      "Epoch 96/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 1.8878 - accuracy: 0.4836 - top-5-accuracy: 0.8005 - val_loss: 2.0990 - val_accuracy: 0.4566 - val_top-5-accuracy: 0.7418\n",
      "Epoch 97/100\n",
      "176/176 [==============================] - 22s 125ms/step - loss: 1.9043 - accuracy: 0.4783 - top-5-accuracy: 0.7972 - val_loss: 2.1037 - val_accuracy: 0.4602 - val_top-5-accuracy: 0.7364\n",
      "Epoch 98/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 1.8936 - accuracy: 0.4799 - top-5-accuracy: 0.8014 - val_loss: 2.0924 - val_accuracy: 0.4562 - val_top-5-accuracy: 0.7438\n",
      "Epoch 99/100\n",
      "176/176 [==============================] - 21s 122ms/step - loss: 1.8865 - accuracy: 0.4812 - top-5-accuracy: 0.8002 - val_loss: 2.0949 - val_accuracy: 0.4594 - val_top-5-accuracy: 0.7490\n",
      "Epoch 100/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 1.8846 - accuracy: 0.4822 - top-5-accuracy: 0.8012 - val_loss: 2.0946 - val_accuracy: 0.4582 - val_top-5-accuracy: 0.7434\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 2.0588 - accuracy: 0.4656 - top-5-accuracy: 0.7552\n",
      "Test accuracy: 46.56%\n",
      "Test top 5 accuracy: 75.52%\n",
      "------------------------\n",
      "6 layers\n",
      "------------------\n",
      "Epoch 1/100\n",
      "176/176 [==============================] - 30s 131ms/step - loss: 4.2719 - accuracy: 0.0652 - top-5-accuracy: 0.2098 - val_loss: 3.7429 - val_accuracy: 0.1318 - val_top-5-accuracy: 0.3508\n",
      "Epoch 2/100\n",
      "176/176 [==============================] - 22s 126ms/step - loss: 3.7982 - accuracy: 0.1193 - top-5-accuracy: 0.3348 - val_loss: 3.4884 - val_accuracy: 0.1718 - val_top-5-accuracy: 0.4278\n",
      "Epoch 3/100\n",
      "176/176 [==============================] - 22s 126ms/step - loss: 3.5946 - accuracy: 0.1514 - top-5-accuracy: 0.3972 - val_loss: 3.2685 - val_accuracy: 0.2102 - val_top-5-accuracy: 0.4804\n",
      "Epoch 4/100\n",
      "176/176 [==============================] - 22s 124ms/step - loss: 3.4533 - accuracy: 0.1742 - top-5-accuracy: 0.4338 - val_loss: 3.2124 - val_accuracy: 0.2170 - val_top-5-accuracy: 0.5040\n",
      "Epoch 5/100\n",
      "176/176 [==============================] - 22s 124ms/step - loss: 3.3554 - accuracy: 0.1916 - top-5-accuracy: 0.4637 - val_loss: 3.1227 - val_accuracy: 0.2340 - val_top-5-accuracy: 0.5194\n",
      "Epoch 6/100\n",
      "176/176 [==============================] - 22s 124ms/step - loss: 3.2702 - accuracy: 0.2065 - top-5-accuracy: 0.4851 - val_loss: 3.0344 - val_accuracy: 0.2556 - val_top-5-accuracy: 0.5436\n",
      "Epoch 7/100\n",
      "176/176 [==============================] - 22s 124ms/step - loss: 3.1993 - accuracy: 0.2184 - top-5-accuracy: 0.5046 - val_loss: 2.9543 - val_accuracy: 0.2690 - val_top-5-accuracy: 0.5624\n",
      "Epoch 8/100\n",
      "176/176 [==============================] - 22s 125ms/step - loss: 3.1316 - accuracy: 0.2304 - top-5-accuracy: 0.5204 - val_loss: 2.9332 - val_accuracy: 0.2734 - val_top-5-accuracy: 0.5696\n",
      "Epoch 9/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 3.0826 - accuracy: 0.2410 - top-5-accuracy: 0.5332 - val_loss: 2.8859 - val_accuracy: 0.2854 - val_top-5-accuracy: 0.5764\n",
      "Epoch 10/100\n",
      "176/176 [==============================] - 22s 125ms/step - loss: 3.0284 - accuracy: 0.2512 - top-5-accuracy: 0.5473 - val_loss: 2.8914 - val_accuracy: 0.2872 - val_top-5-accuracy: 0.5770\n",
      "Epoch 11/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 2.9739 - accuracy: 0.2593 - top-5-accuracy: 0.5606 - val_loss: 2.7929 - val_accuracy: 0.3052 - val_top-5-accuracy: 0.5948\n",
      "Epoch 12/100\n",
      "176/176 [==============================] - 22s 125ms/step - loss: 2.9383 - accuracy: 0.2702 - top-5-accuracy: 0.5688 - val_loss: 2.7618 - val_accuracy: 0.3112 - val_top-5-accuracy: 0.6162\n",
      "Epoch 13/100\n",
      "176/176 [==============================] - 22s 124ms/step - loss: 2.9019 - accuracy: 0.2752 - top-5-accuracy: 0.5797 - val_loss: 2.7559 - val_accuracy: 0.3116 - val_top-5-accuracy: 0.6146\n",
      "Epoch 14/100\n",
      "176/176 [==============================] - 22s 126ms/step - loss: 2.8568 - accuracy: 0.2825 - top-5-accuracy: 0.5901 - val_loss: 2.7387 - val_accuracy: 0.3132 - val_top-5-accuracy: 0.6174\n",
      "Epoch 15/100\n",
      "176/176 [==============================] - 22s 124ms/step - loss: 2.8317 - accuracy: 0.2875 - top-5-accuracy: 0.5959 - val_loss: 2.7054 - val_accuracy: 0.3182 - val_top-5-accuracy: 0.6274\n",
      "Epoch 16/100\n",
      "176/176 [==============================] - 22s 126ms/step - loss: 2.7958 - accuracy: 0.2960 - top-5-accuracy: 0.6029 - val_loss: 2.6926 - val_accuracy: 0.3192 - val_top-5-accuracy: 0.6286\n",
      "Epoch 17/100\n",
      "176/176 [==============================] - 22s 125ms/step - loss: 2.7713 - accuracy: 0.3005 - top-5-accuracy: 0.6090 - val_loss: 2.6542 - val_accuracy: 0.3318 - val_top-5-accuracy: 0.6312\n",
      "Epoch 18/100\n",
      "176/176 [==============================] - 22s 126ms/step - loss: 2.7363 - accuracy: 0.3070 - top-5-accuracy: 0.6191 - val_loss: 2.6472 - val_accuracy: 0.3334 - val_top-5-accuracy: 0.6346\n",
      "Epoch 19/100\n",
      "176/176 [==============================] - 22s 125ms/step - loss: 2.6976 - accuracy: 0.3170 - top-5-accuracy: 0.6278 - val_loss: 2.5748 - val_accuracy: 0.3480 - val_top-5-accuracy: 0.6502\n",
      "Epoch 20/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 2.6794 - accuracy: 0.3176 - top-5-accuracy: 0.6321 - val_loss: 2.5694 - val_accuracy: 0.3470 - val_top-5-accuracy: 0.6516\n",
      "Epoch 21/100\n",
      "176/176 [==============================] - 22s 125ms/step - loss: 2.6473 - accuracy: 0.3230 - top-5-accuracy: 0.6376 - val_loss: 2.5432 - val_accuracy: 0.3552 - val_top-5-accuracy: 0.6608\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/100\n",
      "176/176 [==============================] - 22s 125ms/step - loss: 2.6214 - accuracy: 0.3288 - top-5-accuracy: 0.6437 - val_loss: 2.5226 - val_accuracy: 0.3614 - val_top-5-accuracy: 0.6636\n",
      "Epoch 23/100\n",
      "176/176 [==============================] - 22s 124ms/step - loss: 2.6011 - accuracy: 0.3327 - top-5-accuracy: 0.6476 - val_loss: 2.5223 - val_accuracy: 0.3634 - val_top-5-accuracy: 0.6670\n",
      "Epoch 24/100\n",
      "176/176 [==============================] - 22s 124ms/step - loss: 2.5817 - accuracy: 0.3403 - top-5-accuracy: 0.6542 - val_loss: 2.5121 - val_accuracy: 0.3692 - val_top-5-accuracy: 0.6644\n",
      "Epoch 25/100\n",
      "176/176 [==============================] - 21s 122ms/step - loss: 2.5604 - accuracy: 0.3410 - top-5-accuracy: 0.6575 - val_loss: 2.4807 - val_accuracy: 0.3674 - val_top-5-accuracy: 0.6690\n",
      "Epoch 26/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 2.5277 - accuracy: 0.3495 - top-5-accuracy: 0.6642 - val_loss: 2.4582 - val_accuracy: 0.3804 - val_top-5-accuracy: 0.6780\n",
      "Epoch 27/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 2.5051 - accuracy: 0.3560 - top-5-accuracy: 0.6713 - val_loss: 2.4755 - val_accuracy: 0.3714 - val_top-5-accuracy: 0.6682\n",
      "Epoch 28/100\n",
      "176/176 [==============================] - 21s 122ms/step - loss: 2.4849 - accuracy: 0.3578 - top-5-accuracy: 0.6765 - val_loss: 2.4760 - val_accuracy: 0.3690 - val_top-5-accuracy: 0.6702\n",
      "Epoch 29/100\n",
      "176/176 [==============================] - 22s 124ms/step - loss: 2.4681 - accuracy: 0.3601 - top-5-accuracy: 0.6793 - val_loss: 2.4191 - val_accuracy: 0.3792 - val_top-5-accuracy: 0.6868\n",
      "Epoch 30/100\n",
      "176/176 [==============================] - 22s 124ms/step - loss: 2.4475 - accuracy: 0.3653 - top-5-accuracy: 0.6833 - val_loss: 2.4167 - val_accuracy: 0.3866 - val_top-5-accuracy: 0.6822\n",
      "Epoch 31/100\n",
      "176/176 [==============================] - 22s 126ms/step - loss: 2.4438 - accuracy: 0.3667 - top-5-accuracy: 0.6836 - val_loss: 2.4171 - val_accuracy: 0.3876 - val_top-5-accuracy: 0.6842\n",
      "Epoch 32/100\n",
      "176/176 [==============================] - 22s 125ms/step - loss: 2.4200 - accuracy: 0.3694 - top-5-accuracy: 0.6881 - val_loss: 2.3997 - val_accuracy: 0.3892 - val_top-5-accuracy: 0.6866\n",
      "Epoch 33/100\n",
      "176/176 [==============================] - 22s 126ms/step - loss: 2.4037 - accuracy: 0.3725 - top-5-accuracy: 0.6935 - val_loss: 2.3811 - val_accuracy: 0.3908 - val_top-5-accuracy: 0.6870\n",
      "Epoch 34/100\n",
      "176/176 [==============================] - 22s 125ms/step - loss: 2.3933 - accuracy: 0.3762 - top-5-accuracy: 0.6962 - val_loss: 2.3644 - val_accuracy: 0.4000 - val_top-5-accuracy: 0.7002\n",
      "Epoch 35/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 2.3742 - accuracy: 0.3780 - top-5-accuracy: 0.6989 - val_loss: 2.3855 - val_accuracy: 0.3920 - val_top-5-accuracy: 0.6872\n",
      "Epoch 36/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 2.3634 - accuracy: 0.3812 - top-5-accuracy: 0.7038 - val_loss: 2.3751 - val_accuracy: 0.3964 - val_top-5-accuracy: 0.6916\n",
      "Epoch 37/100\n",
      "176/176 [==============================] - 22s 125ms/step - loss: 2.3382 - accuracy: 0.3854 - top-5-accuracy: 0.7100 - val_loss: 2.3580 - val_accuracy: 0.4072 - val_top-5-accuracy: 0.6958\n",
      "Epoch 38/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 2.3310 - accuracy: 0.3894 - top-5-accuracy: 0.7088 - val_loss: 2.3536 - val_accuracy: 0.4000 - val_top-5-accuracy: 0.6924\n",
      "Epoch 39/100\n",
      "176/176 [==============================] - 22s 122ms/step - loss: 2.3105 - accuracy: 0.3910 - top-5-accuracy: 0.7139 - val_loss: 2.3437 - val_accuracy: 0.4004 - val_top-5-accuracy: 0.7006\n",
      "Epoch 40/100\n",
      "176/176 [==============================] - 22s 125ms/step - loss: 2.3069 - accuracy: 0.3933 - top-5-accuracy: 0.7142 - val_loss: 2.3259 - val_accuracy: 0.4074 - val_top-5-accuracy: 0.7028\n",
      "Epoch 41/100\n",
      "176/176 [==============================] - 22s 124ms/step - loss: 2.2842 - accuracy: 0.3991 - top-5-accuracy: 0.7183 - val_loss: 2.3139 - val_accuracy: 0.4082 - val_top-5-accuracy: 0.7002\n",
      "Epoch 42/100\n",
      "176/176 [==============================] - 22s 125ms/step - loss: 2.2708 - accuracy: 0.4005 - top-5-accuracy: 0.7213 - val_loss: 2.3096 - val_accuracy: 0.4152 - val_top-5-accuracy: 0.7086\n",
      "Epoch 43/100\n",
      "176/176 [==============================] - 21s 121ms/step - loss: 2.2724 - accuracy: 0.4014 - top-5-accuracy: 0.7235 - val_loss: 2.3280 - val_accuracy: 0.4136 - val_top-5-accuracy: 0.7002\n",
      "Epoch 44/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 2.2584 - accuracy: 0.4025 - top-5-accuracy: 0.7229 - val_loss: 2.3069 - val_accuracy: 0.4102 - val_top-5-accuracy: 0.7032\n",
      "Epoch 45/100\n",
      "176/176 [==============================] - 21s 122ms/step - loss: 2.2484 - accuracy: 0.4055 - top-5-accuracy: 0.7279 - val_loss: 2.3079 - val_accuracy: 0.4150 - val_top-5-accuracy: 0.7058\n",
      "Epoch 46/100\n",
      "176/176 [==============================] - 22s 126ms/step - loss: 2.2300 - accuracy: 0.4114 - top-5-accuracy: 0.7331 - val_loss: 2.2771 - val_accuracy: 0.4196 - val_top-5-accuracy: 0.7122\n",
      "Epoch 47/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 2.2215 - accuracy: 0.4149 - top-5-accuracy: 0.7335 - val_loss: 2.2850 - val_accuracy: 0.4192 - val_top-5-accuracy: 0.7084\n",
      "Epoch 48/100\n",
      "176/176 [==============================] - 22s 124ms/step - loss: 2.2140 - accuracy: 0.4136 - top-5-accuracy: 0.7352 - val_loss: 2.2878 - val_accuracy: 0.4142 - val_top-5-accuracy: 0.7022\n",
      "Epoch 49/100\n",
      "176/176 [==============================] - 21s 122ms/step - loss: 2.2071 - accuracy: 0.4146 - top-5-accuracy: 0.7350 - val_loss: 2.3005 - val_accuracy: 0.4102 - val_top-5-accuracy: 0.7044\n",
      "Epoch 50/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 2.1882 - accuracy: 0.4209 - top-5-accuracy: 0.7382 - val_loss: 2.2889 - val_accuracy: 0.4168 - val_top-5-accuracy: 0.7070\n",
      "Epoch 51/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 2.1834 - accuracy: 0.4202 - top-5-accuracy: 0.7392 - val_loss: 2.2687 - val_accuracy: 0.4208 - val_top-5-accuracy: 0.7126\n",
      "Epoch 52/100\n",
      "176/176 [==============================] - 22s 125ms/step - loss: 2.1861 - accuracy: 0.4174 - top-5-accuracy: 0.7398 - val_loss: 2.2456 - val_accuracy: 0.4260 - val_top-5-accuracy: 0.7114\n",
      "Epoch 53/100\n",
      "176/176 [==============================] - 21s 122ms/step - loss: 2.1745 - accuracy: 0.4198 - top-5-accuracy: 0.7431 - val_loss: 2.2616 - val_accuracy: 0.4218 - val_top-5-accuracy: 0.7094\n",
      "Epoch 54/100\n",
      "176/176 [==============================] - 22s 124ms/step - loss: 2.1612 - accuracy: 0.4250 - top-5-accuracy: 0.7452 - val_loss: 2.2521 - val_accuracy: 0.4302 - val_top-5-accuracy: 0.7160\n",
      "Epoch 55/100\n",
      "176/176 [==============================] - 21s 122ms/step - loss: 2.1583 - accuracy: 0.4248 - top-5-accuracy: 0.7467 - val_loss: 2.2522 - val_accuracy: 0.4256 - val_top-5-accuracy: 0.7124\n",
      "Epoch 56/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 2.1422 - accuracy: 0.4281 - top-5-accuracy: 0.7494 - val_loss: 2.2420 - val_accuracy: 0.4324 - val_top-5-accuracy: 0.7214\n",
      "Epoch 57/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 2.1413 - accuracy: 0.4267 - top-5-accuracy: 0.7495 - val_loss: 2.2454 - val_accuracy: 0.4320 - val_top-5-accuracy: 0.7220\n",
      "Epoch 58/100\n",
      "176/176 [==============================] - 21s 121ms/step - loss: 2.1253 - accuracy: 0.4306 - top-5-accuracy: 0.7527 - val_loss: 2.2352 - val_accuracy: 0.4292 - val_top-5-accuracy: 0.7154\n",
      "Epoch 59/100\n",
      "176/176 [==============================] - 22s 124ms/step - loss: 2.1253 - accuracy: 0.4308 - top-5-accuracy: 0.7552 - val_loss: 2.2358 - val_accuracy: 0.4356 - val_top-5-accuracy: 0.7206\n",
      "Epoch 60/100\n",
      "176/176 [==============================] - 21s 120ms/step - loss: 2.1120 - accuracy: 0.4356 - top-5-accuracy: 0.7576 - val_loss: 2.2549 - val_accuracy: 0.4296 - val_top-5-accuracy: 0.7118\n",
      "Epoch 61/100\n",
      "176/176 [==============================] - 22s 124ms/step - loss: 2.1013 - accuracy: 0.4375 - top-5-accuracy: 0.7587 - val_loss: 2.2542 - val_accuracy: 0.4248 - val_top-5-accuracy: 0.7134\n",
      "Epoch 62/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 2.0936 - accuracy: 0.4351 - top-5-accuracy: 0.7577 - val_loss: 2.2245 - val_accuracy: 0.4290 - val_top-5-accuracy: 0.7192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/100\n",
      "176/176 [==============================] - 22s 126ms/step - loss: 2.0930 - accuracy: 0.4390 - top-5-accuracy: 0.7619 - val_loss: 2.2237 - val_accuracy: 0.4380 - val_top-5-accuracy: 0.7200\n",
      "Epoch 64/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 2.0786 - accuracy: 0.4412 - top-5-accuracy: 0.7643 - val_loss: 2.2260 - val_accuracy: 0.4310 - val_top-5-accuracy: 0.7190\n",
      "Epoch 65/100\n",
      "176/176 [==============================] - 22s 124ms/step - loss: 2.0832 - accuracy: 0.4382 - top-5-accuracy: 0.7626 - val_loss: 2.2322 - val_accuracy: 0.4330 - val_top-5-accuracy: 0.7168\n",
      "Epoch 66/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 2.0535 - accuracy: 0.4456 - top-5-accuracy: 0.7692 - val_loss: 2.2036 - val_accuracy: 0.4368 - val_top-5-accuracy: 0.7250\n",
      "Epoch 67/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 2.0471 - accuracy: 0.4466 - top-5-accuracy: 0.7691 - val_loss: 2.2043 - val_accuracy: 0.4378 - val_top-5-accuracy: 0.7246\n",
      "Epoch 68/100\n",
      "176/176 [==============================] - 22s 125ms/step - loss: 2.0461 - accuracy: 0.4459 - top-5-accuracy: 0.7701 - val_loss: 2.2156 - val_accuracy: 0.4414 - val_top-5-accuracy: 0.7236\n",
      "Epoch 69/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 2.0576 - accuracy: 0.4461 - top-5-accuracy: 0.7664 - val_loss: 2.2210 - val_accuracy: 0.4306 - val_top-5-accuracy: 0.7208\n",
      "Epoch 70/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 2.0316 - accuracy: 0.4517 - top-5-accuracy: 0.7717 - val_loss: 2.2075 - val_accuracy: 0.4294 - val_top-5-accuracy: 0.7266\n",
      "Epoch 71/100\n",
      "176/176 [==============================] - 22s 122ms/step - loss: 2.0390 - accuracy: 0.4511 - top-5-accuracy: 0.7691 - val_loss: 2.2038 - val_accuracy: 0.4392 - val_top-5-accuracy: 0.7196\n",
      "Epoch 72/100\n",
      "176/176 [==============================] - 21s 122ms/step - loss: 2.0396 - accuracy: 0.4495 - top-5-accuracy: 0.7710 - val_loss: 2.2060 - val_accuracy: 0.4398 - val_top-5-accuracy: 0.7266\n",
      "Epoch 73/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 2.0197 - accuracy: 0.4539 - top-5-accuracy: 0.7750 - val_loss: 2.1971 - val_accuracy: 0.4420 - val_top-5-accuracy: 0.7284\n",
      "Epoch 74/100\n",
      "176/176 [==============================] - 22s 125ms/step - loss: 2.0149 - accuracy: 0.4534 - top-5-accuracy: 0.7760 - val_loss: 2.1908 - val_accuracy: 0.4468 - val_top-5-accuracy: 0.7254\n",
      "Epoch 75/100\n",
      "176/176 [==============================] - 21s 122ms/step - loss: 2.0098 - accuracy: 0.4546 - top-5-accuracy: 0.7740 - val_loss: 2.1948 - val_accuracy: 0.4372 - val_top-5-accuracy: 0.7282\n",
      "Epoch 76/100\n",
      "176/176 [==============================] - 22s 125ms/step - loss: 2.0151 - accuracy: 0.4563 - top-5-accuracy: 0.7734 - val_loss: 2.1853 - val_accuracy: 0.4472 - val_top-5-accuracy: 0.7250\n",
      "Epoch 77/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 2.0008 - accuracy: 0.4578 - top-5-accuracy: 0.7787 - val_loss: 2.1776 - val_accuracy: 0.4430 - val_top-5-accuracy: 0.7344\n",
      "Epoch 78/100\n",
      "176/176 [==============================] - 22s 124ms/step - loss: 2.0049 - accuracy: 0.4580 - top-5-accuracy: 0.7775 - val_loss: 2.1900 - val_accuracy: 0.4364 - val_top-5-accuracy: 0.7302\n",
      "Epoch 79/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 1.9940 - accuracy: 0.4601 - top-5-accuracy: 0.7821 - val_loss: 2.1817 - val_accuracy: 0.4394 - val_top-5-accuracy: 0.7314\n",
      "Epoch 80/100\n",
      "176/176 [==============================] - 22s 124ms/step - loss: 1.9968 - accuracy: 0.4576 - top-5-accuracy: 0.7819 - val_loss: 2.2025 - val_accuracy: 0.4366 - val_top-5-accuracy: 0.7222\n",
      "Epoch 81/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 1.9799 - accuracy: 0.4647 - top-5-accuracy: 0.7819 - val_loss: 2.1615 - val_accuracy: 0.4468 - val_top-5-accuracy: 0.7330\n",
      "Epoch 82/100\n",
      "176/176 [==============================] - 22s 124ms/step - loss: 1.9809 - accuracy: 0.4631 - top-5-accuracy: 0.7831 - val_loss: 2.1732 - val_accuracy: 0.4362 - val_top-5-accuracy: 0.7330\n",
      "Epoch 83/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 1.9703 - accuracy: 0.4666 - top-5-accuracy: 0.7840 - val_loss: 2.1540 - val_accuracy: 0.4478 - val_top-5-accuracy: 0.7394\n",
      "Epoch 84/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 1.9734 - accuracy: 0.4633 - top-5-accuracy: 0.7834 - val_loss: 2.1814 - val_accuracy: 0.4394 - val_top-5-accuracy: 0.7344\n",
      "Epoch 85/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 1.9691 - accuracy: 0.4617 - top-5-accuracy: 0.7877 - val_loss: 2.1601 - val_accuracy: 0.4448 - val_top-5-accuracy: 0.7360\n",
      "Epoch 86/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 1.9654 - accuracy: 0.4683 - top-5-accuracy: 0.7866 - val_loss: 2.1516 - val_accuracy: 0.4460 - val_top-5-accuracy: 0.7352\n",
      "Epoch 87/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 1.9517 - accuracy: 0.4676 - top-5-accuracy: 0.7905 - val_loss: 2.1694 - val_accuracy: 0.4408 - val_top-5-accuracy: 0.7366\n",
      "Epoch 88/100\n",
      "176/176 [==============================] - 22s 122ms/step - loss: 1.9443 - accuracy: 0.4695 - top-5-accuracy: 0.7904 - val_loss: 2.1491 - val_accuracy: 0.4442 - val_top-5-accuracy: 0.7360\n",
      "Epoch 89/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 1.9431 - accuracy: 0.4709 - top-5-accuracy: 0.7888 - val_loss: 2.1383 - val_accuracy: 0.4460 - val_top-5-accuracy: 0.7378\n",
      "Epoch 90/100\n",
      "176/176 [==============================] - 21s 122ms/step - loss: 1.9348 - accuracy: 0.4726 - top-5-accuracy: 0.7919 - val_loss: 2.1598 - val_accuracy: 0.4430 - val_top-5-accuracy: 0.7364\n",
      "Epoch 91/100\n",
      "176/176 [==============================] - 22s 125ms/step - loss: 1.9482 - accuracy: 0.4702 - top-5-accuracy: 0.7911 - val_loss: 2.1264 - val_accuracy: 0.4504 - val_top-5-accuracy: 0.7448\n",
      "Epoch 92/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 1.9250 - accuracy: 0.4716 - top-5-accuracy: 0.7931 - val_loss: 2.1241 - val_accuracy: 0.4566 - val_top-5-accuracy: 0.7408\n",
      "Epoch 93/100\n",
      "176/176 [==============================] - 21s 122ms/step - loss: 1.9332 - accuracy: 0.4723 - top-5-accuracy: 0.7910 - val_loss: 2.1313 - val_accuracy: 0.4532 - val_top-5-accuracy: 0.7444\n",
      "Epoch 94/100\n",
      "176/176 [==============================] - 21s 121ms/step - loss: 1.9333 - accuracy: 0.4732 - top-5-accuracy: 0.7912 - val_loss: 2.1242 - val_accuracy: 0.4554 - val_top-5-accuracy: 0.7420\n",
      "Epoch 95/100\n",
      "176/176 [==============================] - 22s 124ms/step - loss: 1.9120 - accuracy: 0.4754 - top-5-accuracy: 0.7952 - val_loss: 2.1323 - val_accuracy: 0.4560 - val_top-5-accuracy: 0.7430\n",
      "Epoch 96/100\n",
      "176/176 [==============================] - 21s 122ms/step - loss: 1.9155 - accuracy: 0.4754 - top-5-accuracy: 0.7960 - val_loss: 2.1276 - val_accuracy: 0.4490 - val_top-5-accuracy: 0.7368\n",
      "Epoch 97/100\n",
      "176/176 [==============================] - 22s 125ms/step - loss: 1.9120 - accuracy: 0.4759 - top-5-accuracy: 0.7963 - val_loss: 2.1278 - val_accuracy: 0.4606 - val_top-5-accuracy: 0.7392\n",
      "Epoch 98/100\n",
      "176/176 [==============================] - 21s 121ms/step - loss: 1.9061 - accuracy: 0.4782 - top-5-accuracy: 0.7988 - val_loss: 2.1271 - val_accuracy: 0.4544 - val_top-5-accuracy: 0.7422\n",
      "Epoch 99/100\n",
      "176/176 [==============================] - 22s 125ms/step - loss: 1.8985 - accuracy: 0.4797 - top-5-accuracy: 0.7984 - val_loss: 2.1184 - val_accuracy: 0.4624 - val_top-5-accuracy: 0.7500\n",
      "Epoch 100/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 1.9026 - accuracy: 0.4766 - top-5-accuracy: 0.7979 - val_loss: 2.1389 - val_accuracy: 0.4586 - val_top-5-accuracy: 0.7418\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 2.0756 - accuracy: 0.4642 - top-5-accuracy: 0.7469\n",
      "Test accuracy: 46.42%\n",
      "Test top 5 accuracy: 74.69%\n",
      "------------------------\n",
      "8 layers\n",
      "------------------\n",
      "Epoch 1/100\n",
      "176/176 [==============================] - 30s 132ms/step - loss: 4.2447 - accuracy: 0.0680 - top-5-accuracy: 0.2172 - val_loss: 3.7134 - val_accuracy: 0.1354 - val_top-5-accuracy: 0.3686\n",
      "Epoch 2/100\n",
      "176/176 [==============================] - 22s 125ms/step - loss: 3.7834 - accuracy: 0.1213 - top-5-accuracy: 0.3408 - val_loss: 3.4364 - val_accuracy: 0.1768 - val_top-5-accuracy: 0.4346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/100\n",
      "176/176 [==============================] - 22s 125ms/step - loss: 3.5811 - accuracy: 0.1532 - top-5-accuracy: 0.4019 - val_loss: 3.2909 - val_accuracy: 0.2082 - val_top-5-accuracy: 0.4726\n",
      "Epoch 4/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 3.4415 - accuracy: 0.1766 - top-5-accuracy: 0.4405 - val_loss: 3.1713 - val_accuracy: 0.2300 - val_top-5-accuracy: 0.5044\n",
      "Epoch 5/100\n",
      "176/176 [==============================] - 22s 126ms/step - loss: 3.3549 - accuracy: 0.1916 - top-5-accuracy: 0.4644 - val_loss: 3.0764 - val_accuracy: 0.2506 - val_top-5-accuracy: 0.5308\n",
      "Epoch 6/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 3.2605 - accuracy: 0.2091 - top-5-accuracy: 0.4871 - val_loss: 3.0396 - val_accuracy: 0.2496 - val_top-5-accuracy: 0.5380\n",
      "Epoch 7/100\n",
      "176/176 [==============================] - 22s 127ms/step - loss: 3.2049 - accuracy: 0.2203 - top-5-accuracy: 0.5038 - val_loss: 2.9755 - val_accuracy: 0.2644 - val_top-5-accuracy: 0.5560\n",
      "Epoch 8/100\n",
      "176/176 [==============================] - 22s 125ms/step - loss: 3.1277 - accuracy: 0.2327 - top-5-accuracy: 0.5228 - val_loss: 2.9697 - val_accuracy: 0.2690 - val_top-5-accuracy: 0.5624\n",
      "Epoch 9/100\n",
      "176/176 [==============================] - 22s 126ms/step - loss: 3.0888 - accuracy: 0.2387 - top-5-accuracy: 0.5311 - val_loss: 2.8860 - val_accuracy: 0.2890 - val_top-5-accuracy: 0.5704\n",
      "Epoch 10/100\n",
      "176/176 [==============================] - 22s 125ms/step - loss: 3.0181 - accuracy: 0.2532 - top-5-accuracy: 0.5502 - val_loss: 2.8200 - val_accuracy: 0.2994 - val_top-5-accuracy: 0.5954\n",
      "Epoch 11/100\n",
      "176/176 [==============================] - 22s 124ms/step - loss: 2.9821 - accuracy: 0.2623 - top-5-accuracy: 0.5597 - val_loss: 2.8358 - val_accuracy: 0.2936 - val_top-5-accuracy: 0.5898\n",
      "Epoch 12/100\n",
      "176/176 [==============================] - 22s 125ms/step - loss: 2.9350 - accuracy: 0.2717 - top-5-accuracy: 0.5688 - val_loss: 2.7710 - val_accuracy: 0.3040 - val_top-5-accuracy: 0.6060\n",
      "Epoch 13/100\n",
      "176/176 [==============================] - 22s 126ms/step - loss: 2.8990 - accuracy: 0.2713 - top-5-accuracy: 0.5816 - val_loss: 2.7374 - val_accuracy: 0.3156 - val_top-5-accuracy: 0.6114\n",
      "Epoch 14/100\n",
      "176/176 [==============================] - 22s 125ms/step - loss: 2.8589 - accuracy: 0.2831 - top-5-accuracy: 0.5896 - val_loss: 2.7016 - val_accuracy: 0.3248 - val_top-5-accuracy: 0.6204\n",
      "Epoch 15/100\n",
      "176/176 [==============================] - 22s 124ms/step - loss: 2.8234 - accuracy: 0.2900 - top-5-accuracy: 0.5979 - val_loss: 2.6824 - val_accuracy: 0.3268 - val_top-5-accuracy: 0.6258\n",
      "Epoch 16/100\n",
      "176/176 [==============================] - 22s 125ms/step - loss: 2.7894 - accuracy: 0.2950 - top-5-accuracy: 0.6070 - val_loss: 2.6568 - val_accuracy: 0.3338 - val_top-5-accuracy: 0.6316\n",
      "Epoch 17/100\n",
      "176/176 [==============================] - 22s 125ms/step - loss: 2.7566 - accuracy: 0.3034 - top-5-accuracy: 0.6130 - val_loss: 2.6014 - val_accuracy: 0.3472 - val_top-5-accuracy: 0.6426\n",
      "Epoch 18/100\n",
      "176/176 [==============================] - 22s 125ms/step - loss: 2.7337 - accuracy: 0.3075 - top-5-accuracy: 0.6179 - val_loss: 2.5840 - val_accuracy: 0.3502 - val_top-5-accuracy: 0.6518\n",
      "Epoch 19/100\n",
      "176/176 [==============================] - 21s 122ms/step - loss: 2.7005 - accuracy: 0.3126 - top-5-accuracy: 0.6276 - val_loss: 2.5857 - val_accuracy: 0.3486 - val_top-5-accuracy: 0.6500\n",
      "Epoch 20/100\n",
      "176/176 [==============================] - 22s 125ms/step - loss: 2.6748 - accuracy: 0.3162 - top-5-accuracy: 0.6308 - val_loss: 2.5548 - val_accuracy: 0.3504 - val_top-5-accuracy: 0.6572\n",
      "Epoch 21/100\n",
      "176/176 [==============================] - 22s 124ms/step - loss: 2.6458 - accuracy: 0.3231 - top-5-accuracy: 0.6423 - val_loss: 2.5234 - val_accuracy: 0.3644 - val_top-5-accuracy: 0.6666\n",
      "Epoch 22/100\n",
      "176/176 [==============================] - 22s 125ms/step - loss: 2.6387 - accuracy: 0.3237 - top-5-accuracy: 0.6396 - val_loss: 2.5280 - val_accuracy: 0.3598 - val_top-5-accuracy: 0.6606\n",
      "Epoch 23/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 2.6055 - accuracy: 0.3337 - top-5-accuracy: 0.6460 - val_loss: 2.5053 - val_accuracy: 0.3606 - val_top-5-accuracy: 0.6654\n",
      "Epoch 24/100\n",
      "176/176 [==============================] - 22s 126ms/step - loss: 2.5781 - accuracy: 0.3383 - top-5-accuracy: 0.6551 - val_loss: 2.4812 - val_accuracy: 0.3676 - val_top-5-accuracy: 0.6684\n",
      "Epoch 25/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 2.5574 - accuracy: 0.3415 - top-5-accuracy: 0.6568 - val_loss: 2.4705 - val_accuracy: 0.3736 - val_top-5-accuracy: 0.6710\n",
      "Epoch 26/100\n",
      "176/176 [==============================] - 22s 125ms/step - loss: 2.5315 - accuracy: 0.3455 - top-5-accuracy: 0.6655 - val_loss: 2.4553 - val_accuracy: 0.3832 - val_top-5-accuracy: 0.6746\n",
      "Epoch 27/100\n",
      "176/176 [==============================] - 22s 125ms/step - loss: 2.5093 - accuracy: 0.3546 - top-5-accuracy: 0.6682 - val_loss: 2.4392 - val_accuracy: 0.3834 - val_top-5-accuracy: 0.6772\n",
      "Epoch 28/100\n",
      "176/176 [==============================] - 22s 124ms/step - loss: 2.4845 - accuracy: 0.3579 - top-5-accuracy: 0.6740 - val_loss: 2.4465 - val_accuracy: 0.3792 - val_top-5-accuracy: 0.6756\n",
      "Epoch 29/100\n",
      "176/176 [==============================] - 22s 125ms/step - loss: 2.4771 - accuracy: 0.3569 - top-5-accuracy: 0.6773 - val_loss: 2.4180 - val_accuracy: 0.3868 - val_top-5-accuracy: 0.6780\n",
      "Epoch 30/100\n",
      "176/176 [==============================] - 22s 126ms/step - loss: 2.4562 - accuracy: 0.3629 - top-5-accuracy: 0.6806 - val_loss: 2.4042 - val_accuracy: 0.3904 - val_top-5-accuracy: 0.6860\n",
      "Epoch 31/100\n",
      "176/176 [==============================] - 22s 125ms/step - loss: 2.4357 - accuracy: 0.3651 - top-5-accuracy: 0.6847 - val_loss: 2.3902 - val_accuracy: 0.3944 - val_top-5-accuracy: 0.6894\n",
      "Epoch 32/100\n",
      "176/176 [==============================] - 22s 126ms/step - loss: 2.4209 - accuracy: 0.3710 - top-5-accuracy: 0.6904 - val_loss: 2.3735 - val_accuracy: 0.3974 - val_top-5-accuracy: 0.6896\n",
      "Epoch 33/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 2.4022 - accuracy: 0.3741 - top-5-accuracy: 0.6945 - val_loss: 2.3693 - val_accuracy: 0.3938 - val_top-5-accuracy: 0.6920\n",
      "Epoch 34/100\n",
      "176/176 [==============================] - 22s 125ms/step - loss: 2.3882 - accuracy: 0.3739 - top-5-accuracy: 0.6963 - val_loss: 2.3562 - val_accuracy: 0.3976 - val_top-5-accuracy: 0.6962\n",
      "Epoch 35/100\n",
      "176/176 [==============================] - 22s 125ms/step - loss: 2.3784 - accuracy: 0.3757 - top-5-accuracy: 0.6986 - val_loss: 2.3472 - val_accuracy: 0.4062 - val_top-5-accuracy: 0.6968\n",
      "Epoch 36/100\n",
      "176/176 [==============================] - 22s 124ms/step - loss: 2.3618 - accuracy: 0.3820 - top-5-accuracy: 0.7018 - val_loss: 2.3522 - val_accuracy: 0.4070 - val_top-5-accuracy: 0.6938\n",
      "Epoch 37/100\n",
      "176/176 [==============================] - 22s 124ms/step - loss: 2.3500 - accuracy: 0.3836 - top-5-accuracy: 0.7054 - val_loss: 2.3364 - val_accuracy: 0.4100 - val_top-5-accuracy: 0.7006\n",
      "Epoch 38/100\n",
      "176/176 [==============================] - 21s 121ms/step - loss: 2.3376 - accuracy: 0.3878 - top-5-accuracy: 0.7064 - val_loss: 2.3527 - val_accuracy: 0.3986 - val_top-5-accuracy: 0.6974\n",
      "Epoch 39/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 2.3211 - accuracy: 0.3894 - top-5-accuracy: 0.7083 - val_loss: 2.3339 - val_accuracy: 0.4056 - val_top-5-accuracy: 0.6962\n",
      "Epoch 40/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 2.3109 - accuracy: 0.3934 - top-5-accuracy: 0.7130 - val_loss: 2.2905 - val_accuracy: 0.4228 - val_top-5-accuracy: 0.7064\n",
      "Epoch 41/100\n",
      "176/176 [==============================] - 22s 125ms/step - loss: 2.2963 - accuracy: 0.3957 - top-5-accuracy: 0.7167 - val_loss: 2.3116 - val_accuracy: 0.4148 - val_top-5-accuracy: 0.7040\n",
      "Epoch 42/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 2.2783 - accuracy: 0.3992 - top-5-accuracy: 0.7206 - val_loss: 2.3054 - val_accuracy: 0.4116 - val_top-5-accuracy: 0.7032\n",
      "Epoch 43/100\n",
      "176/176 [==============================] - 22s 124ms/step - loss: 2.2724 - accuracy: 0.3990 - top-5-accuracy: 0.7221 - val_loss: 2.3097 - val_accuracy: 0.4144 - val_top-5-accuracy: 0.7108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/100\n",
      "176/176 [==============================] - 21s 122ms/step - loss: 2.2513 - accuracy: 0.4041 - top-5-accuracy: 0.7270 - val_loss: 2.2944 - val_accuracy: 0.4116 - val_top-5-accuracy: 0.7080\n",
      "Epoch 45/100\n",
      "176/176 [==============================] - 22s 125ms/step - loss: 2.2642 - accuracy: 0.4028 - top-5-accuracy: 0.7241 - val_loss: 2.2759 - val_accuracy: 0.4232 - val_top-5-accuracy: 0.7104\n",
      "Epoch 46/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 2.2353 - accuracy: 0.4076 - top-5-accuracy: 0.7280 - val_loss: 2.2789 - val_accuracy: 0.4206 - val_top-5-accuracy: 0.7080\n",
      "Epoch 47/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 2.2274 - accuracy: 0.4090 - top-5-accuracy: 0.7314 - val_loss: 2.2960 - val_accuracy: 0.4204 - val_top-5-accuracy: 0.7090\n",
      "Epoch 48/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 2.2190 - accuracy: 0.4086 - top-5-accuracy: 0.7316 - val_loss: 2.2736 - val_accuracy: 0.4218 - val_top-5-accuracy: 0.7062\n",
      "Epoch 49/100\n",
      "176/176 [==============================] - 22s 122ms/step - loss: 2.2109 - accuracy: 0.4122 - top-5-accuracy: 0.7336 - val_loss: 2.2843 - val_accuracy: 0.4154 - val_top-5-accuracy: 0.7086\n",
      "Epoch 50/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 2.2072 - accuracy: 0.4136 - top-5-accuracy: 0.7363 - val_loss: 2.2897 - val_accuracy: 0.4142 - val_top-5-accuracy: 0.7042\n",
      "Epoch 51/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 2.1929 - accuracy: 0.4179 - top-5-accuracy: 0.7388 - val_loss: 2.2751 - val_accuracy: 0.4196 - val_top-5-accuracy: 0.7106\n",
      "Epoch 52/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 2.1835 - accuracy: 0.4191 - top-5-accuracy: 0.7414 - val_loss: 2.2516 - val_accuracy: 0.4180 - val_top-5-accuracy: 0.7154\n",
      "Epoch 53/100\n",
      "176/176 [==============================] - 22s 122ms/step - loss: 2.1699 - accuracy: 0.4210 - top-5-accuracy: 0.7452 - val_loss: 2.2483 - val_accuracy: 0.4228 - val_top-5-accuracy: 0.7156\n",
      "Epoch 54/100\n",
      "176/176 [==============================] - 22s 125ms/step - loss: 2.1739 - accuracy: 0.4216 - top-5-accuracy: 0.7436 - val_loss: 2.2504 - val_accuracy: 0.4274 - val_top-5-accuracy: 0.7198\n",
      "Epoch 55/100\n",
      "176/176 [==============================] - 21s 122ms/step - loss: 2.1530 - accuracy: 0.4259 - top-5-accuracy: 0.7483 - val_loss: 2.2534 - val_accuracy: 0.4222 - val_top-5-accuracy: 0.7124\n",
      "Epoch 56/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 2.1493 - accuracy: 0.4264 - top-5-accuracy: 0.7470 - val_loss: 2.2481 - val_accuracy: 0.4278 - val_top-5-accuracy: 0.7198\n",
      "Epoch 57/100\n",
      "176/176 [==============================] - 21s 120ms/step - loss: 2.1367 - accuracy: 0.4278 - top-5-accuracy: 0.7489 - val_loss: 2.2457 - val_accuracy: 0.4210 - val_top-5-accuracy: 0.7124\n",
      "Epoch 58/100\n",
      "176/176 [==============================] - 22s 126ms/step - loss: 2.1395 - accuracy: 0.4260 - top-5-accuracy: 0.7487 - val_loss: 2.2244 - val_accuracy: 0.4308 - val_top-5-accuracy: 0.7250\n",
      "Epoch 59/100\n",
      "176/176 [==============================] - 21s 122ms/step - loss: 2.1242 - accuracy: 0.4331 - top-5-accuracy: 0.7536 - val_loss: 2.2213 - val_accuracy: 0.4264 - val_top-5-accuracy: 0.7224\n",
      "Epoch 60/100\n",
      "176/176 [==============================] - 22s 126ms/step - loss: 2.1267 - accuracy: 0.4290 - top-5-accuracy: 0.7560 - val_loss: 2.2113 - val_accuracy: 0.4378 - val_top-5-accuracy: 0.7234\n",
      "Epoch 61/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 2.1208 - accuracy: 0.4311 - top-5-accuracy: 0.7542 - val_loss: 2.2267 - val_accuracy: 0.4320 - val_top-5-accuracy: 0.7192\n",
      "Epoch 62/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 2.1202 - accuracy: 0.4309 - top-5-accuracy: 0.7549 - val_loss: 2.2241 - val_accuracy: 0.4316 - val_top-5-accuracy: 0.7150\n",
      "Epoch 63/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 2.1127 - accuracy: 0.4314 - top-5-accuracy: 0.7557 - val_loss: 2.2283 - val_accuracy: 0.4348 - val_top-5-accuracy: 0.7218\n",
      "Epoch 64/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 2.0874 - accuracy: 0.4380 - top-5-accuracy: 0.7604 - val_loss: 2.2014 - val_accuracy: 0.4320 - val_top-5-accuracy: 0.7206\n",
      "Epoch 65/100\n",
      "176/176 [==============================] - 21s 122ms/step - loss: 2.0830 - accuracy: 0.4382 - top-5-accuracy: 0.7616 - val_loss: 2.2093 - val_accuracy: 0.4274 - val_top-5-accuracy: 0.7256\n",
      "Epoch 66/100\n",
      "176/176 [==============================] - 22s 122ms/step - loss: 2.0748 - accuracy: 0.4412 - top-5-accuracy: 0.7645 - val_loss: 2.1974 - val_accuracy: 0.4318 - val_top-5-accuracy: 0.7296\n",
      "Epoch 67/100\n",
      "176/176 [==============================] - 21s 122ms/step - loss: 2.0739 - accuracy: 0.4413 - top-5-accuracy: 0.7635 - val_loss: 2.1980 - val_accuracy: 0.4346 - val_top-5-accuracy: 0.7266\n",
      "Epoch 68/100\n",
      "176/176 [==============================] - 22s 122ms/step - loss: 2.0729 - accuracy: 0.4423 - top-5-accuracy: 0.7624 - val_loss: 2.2141 - val_accuracy: 0.4300 - val_top-5-accuracy: 0.7174\n",
      "Epoch 69/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 2.0597 - accuracy: 0.4452 - top-5-accuracy: 0.7652 - val_loss: 2.2021 - val_accuracy: 0.4326 - val_top-5-accuracy: 0.7270\n",
      "Epoch 70/100\n",
      "176/176 [==============================] - 21s 122ms/step - loss: 2.0489 - accuracy: 0.4478 - top-5-accuracy: 0.7680 - val_loss: 2.2068 - val_accuracy: 0.4362 - val_top-5-accuracy: 0.7276\n",
      "Epoch 71/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 2.0542 - accuracy: 0.4446 - top-5-accuracy: 0.7686 - val_loss: 2.1968 - val_accuracy: 0.4338 - val_top-5-accuracy: 0.7232\n",
      "Epoch 72/100\n",
      "176/176 [==============================] - 21s 122ms/step - loss: 2.0511 - accuracy: 0.4467 - top-5-accuracy: 0.7667 - val_loss: 2.1902 - val_accuracy: 0.4378 - val_top-5-accuracy: 0.7256\n",
      "Epoch 73/100\n",
      "176/176 [==============================] - 22s 127ms/step - loss: 2.0265 - accuracy: 0.4523 - top-5-accuracy: 0.7736 - val_loss: 2.1908 - val_accuracy: 0.4412 - val_top-5-accuracy: 0.7250\n",
      "Epoch 74/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 2.0286 - accuracy: 0.4506 - top-5-accuracy: 0.7714 - val_loss: 2.2062 - val_accuracy: 0.4378 - val_top-5-accuracy: 0.7238\n",
      "Epoch 75/100\n",
      "176/176 [==============================] - 22s 124ms/step - loss: 2.0349 - accuracy: 0.4495 - top-5-accuracy: 0.7724 - val_loss: 2.1921 - val_accuracy: 0.4328 - val_top-5-accuracy: 0.7270\n",
      "Epoch 76/100\n",
      "176/176 [==============================] - 21s 121ms/step - loss: 2.0307 - accuracy: 0.4482 - top-5-accuracy: 0.7734 - val_loss: 2.1820 - val_accuracy: 0.4332 - val_top-5-accuracy: 0.7308\n",
      "Epoch 77/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 2.0199 - accuracy: 0.4532 - top-5-accuracy: 0.7723 - val_loss: 2.1923 - val_accuracy: 0.4336 - val_top-5-accuracy: 0.7260\n",
      "Epoch 78/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 2.0096 - accuracy: 0.4591 - top-5-accuracy: 0.7755 - val_loss: 2.1819 - val_accuracy: 0.4388 - val_top-5-accuracy: 0.7288\n",
      "Epoch 79/100\n",
      "176/176 [==============================] - 22s 124ms/step - loss: 1.9998 - accuracy: 0.4593 - top-5-accuracy: 0.7784 - val_loss: 2.1713 - val_accuracy: 0.4396 - val_top-5-accuracy: 0.7342\n",
      "Epoch 80/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 1.9997 - accuracy: 0.4588 - top-5-accuracy: 0.7786 - val_loss: 2.1918 - val_accuracy: 0.4390 - val_top-5-accuracy: 0.7248\n",
      "Epoch 81/100\n",
      "176/176 [==============================] - 22s 125ms/step - loss: 2.0110 - accuracy: 0.4562 - top-5-accuracy: 0.7788 - val_loss: 2.1655 - val_accuracy: 0.4442 - val_top-5-accuracy: 0.7334\n",
      "Epoch 82/100\n",
      "176/176 [==============================] - 22s 125ms/step - loss: 1.9827 - accuracy: 0.4622 - top-5-accuracy: 0.7833 - val_loss: 2.1535 - val_accuracy: 0.4470 - val_top-5-accuracy: 0.7334\n",
      "Epoch 83/100\n",
      "176/176 [==============================] - 22s 124ms/step - loss: 1.9844 - accuracy: 0.4618 - top-5-accuracy: 0.7827 - val_loss: 2.1464 - val_accuracy: 0.4472 - val_top-5-accuracy: 0.7316\n",
      "Epoch 84/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 1.9781 - accuracy: 0.4638 - top-5-accuracy: 0.7830 - val_loss: 2.1628 - val_accuracy: 0.4444 - val_top-5-accuracy: 0.7358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/100\n",
      "176/176 [==============================] - 21s 122ms/step - loss: 1.9712 - accuracy: 0.4645 - top-5-accuracy: 0.7840 - val_loss: 2.1538 - val_accuracy: 0.4414 - val_top-5-accuracy: 0.7352\n",
      "Epoch 86/100\n",
      "176/176 [==============================] - 22s 125ms/step - loss: 1.9801 - accuracy: 0.4644 - top-5-accuracy: 0.7810 - val_loss: 2.1364 - val_accuracy: 0.4492 - val_top-5-accuracy: 0.7350\n",
      "Epoch 87/100\n",
      "176/176 [==============================] - 21s 121ms/step - loss: 1.9674 - accuracy: 0.4654 - top-5-accuracy: 0.7859 - val_loss: 2.1723 - val_accuracy: 0.4404 - val_top-5-accuracy: 0.7260\n",
      "Epoch 88/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 1.9575 - accuracy: 0.4699 - top-5-accuracy: 0.7852 - val_loss: 2.1564 - val_accuracy: 0.4440 - val_top-5-accuracy: 0.7304\n",
      "Epoch 89/100\n",
      "176/176 [==============================] - 22s 124ms/step - loss: 1.9539 - accuracy: 0.4673 - top-5-accuracy: 0.7882 - val_loss: 2.1453 - val_accuracy: 0.4500 - val_top-5-accuracy: 0.7372\n",
      "Epoch 90/100\n",
      "176/176 [==============================] - 22s 125ms/step - loss: 1.9494 - accuracy: 0.4694 - top-5-accuracy: 0.7890 - val_loss: 2.1316 - val_accuracy: 0.4476 - val_top-5-accuracy: 0.7342\n",
      "Epoch 91/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 1.9475 - accuracy: 0.4680 - top-5-accuracy: 0.7881 - val_loss: 2.1372 - val_accuracy: 0.4476 - val_top-5-accuracy: 0.7400\n",
      "Epoch 92/100\n",
      "176/176 [==============================] - 22s 124ms/step - loss: 1.9441 - accuracy: 0.4660 - top-5-accuracy: 0.7886 - val_loss: 2.1519 - val_accuracy: 0.4420 - val_top-5-accuracy: 0.7334\n",
      "Epoch 93/100\n",
      "176/176 [==============================] - 22s 125ms/step - loss: 1.9438 - accuracy: 0.4724 - top-5-accuracy: 0.7900 - val_loss: 2.1425 - val_accuracy: 0.4504 - val_top-5-accuracy: 0.7360\n",
      "Epoch 94/100\n",
      "176/176 [==============================] - 22s 124ms/step - loss: 1.9436 - accuracy: 0.4690 - top-5-accuracy: 0.7896 - val_loss: 2.1634 - val_accuracy: 0.4466 - val_top-5-accuracy: 0.7330\n",
      "Epoch 95/100\n",
      "176/176 [==============================] - 22s 125ms/step - loss: 1.9271 - accuracy: 0.4751 - top-5-accuracy: 0.7938 - val_loss: 2.1317 - val_accuracy: 0.4552 - val_top-5-accuracy: 0.7388\n",
      "Epoch 96/100\n",
      "176/176 [==============================] - 22s 124ms/step - loss: 1.9168 - accuracy: 0.4776 - top-5-accuracy: 0.7946 - val_loss: 2.1236 - val_accuracy: 0.4546 - val_top-5-accuracy: 0.7430\n",
      "Epoch 97/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 1.9109 - accuracy: 0.4788 - top-5-accuracy: 0.7942 - val_loss: 2.1382 - val_accuracy: 0.4534 - val_top-5-accuracy: 0.7370\n",
      "Epoch 98/100\n",
      "176/176 [==============================] - 22s 125ms/step - loss: 1.9273 - accuracy: 0.4738 - top-5-accuracy: 0.7945 - val_loss: 2.1115 - val_accuracy: 0.4616 - val_top-5-accuracy: 0.7386\n",
      "Epoch 99/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 1.9157 - accuracy: 0.4762 - top-5-accuracy: 0.7956 - val_loss: 2.1181 - val_accuracy: 0.4562 - val_top-5-accuracy: 0.7410\n",
      "Epoch 100/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 1.9096 - accuracy: 0.4756 - top-5-accuracy: 0.7983 - val_loss: 2.1298 - val_accuracy: 0.4528 - val_top-5-accuracy: 0.7374\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 2.0844 - accuracy: 0.4665 - top-5-accuracy: 0.7454\n",
      "Test accuracy: 46.65%\n",
      "Test top 5 accuracy: 74.54%\n",
      "------------------------\n",
      "10 layers\n",
      "------------------\n",
      "Epoch 1/100\n",
      "176/176 [==============================] - 30s 130ms/step - loss: 4.2393 - accuracy: 0.0667 - top-5-accuracy: 0.2170 - val_loss: 3.7121 - val_accuracy: 0.1372 - val_top-5-accuracy: 0.3532\n",
      "Epoch 2/100\n",
      "176/176 [==============================] - 22s 126ms/step - loss: 3.7686 - accuracy: 0.1228 - top-5-accuracy: 0.3463 - val_loss: 3.4053 - val_accuracy: 0.1824 - val_top-5-accuracy: 0.4442\n",
      "Epoch 3/100\n",
      "176/176 [==============================] - 22s 124ms/step - loss: 3.5621 - accuracy: 0.1571 - top-5-accuracy: 0.4069 - val_loss: 3.2989 - val_accuracy: 0.2010 - val_top-5-accuracy: 0.4790\n",
      "Epoch 4/100\n",
      "176/176 [==============================] - 22s 126ms/step - loss: 3.4226 - accuracy: 0.1830 - top-5-accuracy: 0.4467 - val_loss: 3.1730 - val_accuracy: 0.2300 - val_top-5-accuracy: 0.5120\n",
      "Epoch 5/100\n",
      "176/176 [==============================] - 22s 125ms/step - loss: 3.3232 - accuracy: 0.1971 - top-5-accuracy: 0.4716 - val_loss: 3.0593 - val_accuracy: 0.2442 - val_top-5-accuracy: 0.5362\n",
      "Epoch 6/100\n",
      "176/176 [==============================] - 22s 125ms/step - loss: 3.2359 - accuracy: 0.2133 - top-5-accuracy: 0.4942 - val_loss: 3.0102 - val_accuracy: 0.2508 - val_top-5-accuracy: 0.5500\n",
      "Epoch 7/100\n",
      "176/176 [==============================] - 22s 125ms/step - loss: 3.1565 - accuracy: 0.2252 - top-5-accuracy: 0.5162 - val_loss: 2.9641 - val_accuracy: 0.2696 - val_top-5-accuracy: 0.5606\n",
      "Epoch 8/100\n",
      "176/176 [==============================] - 22s 125ms/step - loss: 3.0890 - accuracy: 0.2414 - top-5-accuracy: 0.5316 - val_loss: 2.8981 - val_accuracy: 0.2776 - val_top-5-accuracy: 0.5730\n",
      "Epoch 9/100\n",
      "176/176 [==============================] - 22s 125ms/step - loss: 3.0521 - accuracy: 0.2448 - top-5-accuracy: 0.5406 - val_loss: 2.8423 - val_accuracy: 0.2928 - val_top-5-accuracy: 0.5884\n",
      "Epoch 10/100\n",
      "176/176 [==============================] - 22s 124ms/step - loss: 2.9865 - accuracy: 0.2574 - top-5-accuracy: 0.5592 - val_loss: 2.7955 - val_accuracy: 0.2952 - val_top-5-accuracy: 0.6022\n",
      "Epoch 11/100\n",
      "176/176 [==============================] - 22s 125ms/step - loss: 2.9356 - accuracy: 0.2681 - top-5-accuracy: 0.5692 - val_loss: 2.7633 - val_accuracy: 0.3098 - val_top-5-accuracy: 0.6068\n",
      "Epoch 12/100\n",
      "176/176 [==============================] - 21s 121ms/step - loss: 2.8938 - accuracy: 0.2789 - top-5-accuracy: 0.5798 - val_loss: 2.7549 - val_accuracy: 0.3090 - val_top-5-accuracy: 0.6088\n",
      "Epoch 13/100\n",
      "176/176 [==============================] - 22s 125ms/step - loss: 2.8604 - accuracy: 0.2844 - top-5-accuracy: 0.5882 - val_loss: 2.7140 - val_accuracy: 0.3152 - val_top-5-accuracy: 0.6224\n",
      "Epoch 14/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 2.8224 - accuracy: 0.2912 - top-5-accuracy: 0.5996 - val_loss: 2.6674 - val_accuracy: 0.3254 - val_top-5-accuracy: 0.6374\n",
      "Epoch 15/100\n",
      "176/176 [==============================] - 22s 127ms/step - loss: 2.8018 - accuracy: 0.2951 - top-5-accuracy: 0.6058 - val_loss: 2.6536 - val_accuracy: 0.3310 - val_top-5-accuracy: 0.6362\n",
      "Epoch 16/100\n",
      "176/176 [==============================] - 22s 124ms/step - loss: 2.7543 - accuracy: 0.3066 - top-5-accuracy: 0.6146 - val_loss: 2.6263 - val_accuracy: 0.3386 - val_top-5-accuracy: 0.6372\n",
      "Epoch 17/100\n",
      "176/176 [==============================] - 22s 124ms/step - loss: 2.7245 - accuracy: 0.3094 - top-5-accuracy: 0.6227 - val_loss: 2.5934 - val_accuracy: 0.3386 - val_top-5-accuracy: 0.6500\n",
      "Epoch 18/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 2.7024 - accuracy: 0.3105 - top-5-accuracy: 0.6233 - val_loss: 2.5879 - val_accuracy: 0.3470 - val_top-5-accuracy: 0.6466\n",
      "Epoch 19/100\n",
      "176/176 [==============================] - 22s 126ms/step - loss: 2.6643 - accuracy: 0.3226 - top-5-accuracy: 0.6347 - val_loss: 2.5538 - val_accuracy: 0.3546 - val_top-5-accuracy: 0.6574\n",
      "Epoch 20/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 2.6299 - accuracy: 0.3286 - top-5-accuracy: 0.6438 - val_loss: 2.5427 - val_accuracy: 0.3544 - val_top-5-accuracy: 0.6536\n",
      "Epoch 21/100\n",
      "176/176 [==============================] - 22s 125ms/step - loss: 2.6155 - accuracy: 0.3286 - top-5-accuracy: 0.6447 - val_loss: 2.5109 - val_accuracy: 0.3644 - val_top-5-accuracy: 0.6576\n",
      "Epoch 22/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 2.5882 - accuracy: 0.3353 - top-5-accuracy: 0.6552 - val_loss: 2.5042 - val_accuracy: 0.3616 - val_top-5-accuracy: 0.6632\n",
      "Epoch 23/100\n",
      "176/176 [==============================] - 22s 125ms/step - loss: 2.5663 - accuracy: 0.3430 - top-5-accuracy: 0.6550 - val_loss: 2.4816 - val_accuracy: 0.3664 - val_top-5-accuracy: 0.6696\n",
      "Epoch 24/100\n",
      "176/176 [==============================] - 22s 125ms/step - loss: 2.5406 - accuracy: 0.3444 - top-5-accuracy: 0.6613 - val_loss: 2.4779 - val_accuracy: 0.3708 - val_top-5-accuracy: 0.6684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/100\n",
      "176/176 [==============================] - 22s 124ms/step - loss: 2.5171 - accuracy: 0.3507 - top-5-accuracy: 0.6668 - val_loss: 2.4798 - val_accuracy: 0.3776 - val_top-5-accuracy: 0.6738\n",
      "Epoch 26/100\n",
      "176/176 [==============================] - 22s 125ms/step - loss: 2.5049 - accuracy: 0.3515 - top-5-accuracy: 0.6721 - val_loss: 2.4369 - val_accuracy: 0.3804 - val_top-5-accuracy: 0.6762\n",
      "Epoch 27/100\n",
      "176/176 [==============================] - 22s 124ms/step - loss: 2.4868 - accuracy: 0.3580 - top-5-accuracy: 0.6749 - val_loss: 2.4263 - val_accuracy: 0.3830 - val_top-5-accuracy: 0.6828\n",
      "Epoch 28/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 2.4701 - accuracy: 0.3605 - top-5-accuracy: 0.6776 - val_loss: 2.4338 - val_accuracy: 0.3830 - val_top-5-accuracy: 0.6790\n",
      "Epoch 29/100\n",
      "176/176 [==============================] - 22s 124ms/step - loss: 2.4460 - accuracy: 0.3668 - top-5-accuracy: 0.6820 - val_loss: 2.3972 - val_accuracy: 0.3864 - val_top-5-accuracy: 0.6874\n",
      "Epoch 30/100\n",
      "176/176 [==============================] - 22s 125ms/step - loss: 2.4281 - accuracy: 0.3684 - top-5-accuracy: 0.6888 - val_loss: 2.3948 - val_accuracy: 0.3846 - val_top-5-accuracy: 0.6836\n",
      "Epoch 31/100\n",
      "176/176 [==============================] - 22s 125ms/step - loss: 2.4182 - accuracy: 0.3725 - top-5-accuracy: 0.6902 - val_loss: 2.4033 - val_accuracy: 0.3896 - val_top-5-accuracy: 0.6814\n",
      "Epoch 32/100\n",
      "176/176 [==============================] - 22s 126ms/step - loss: 2.3976 - accuracy: 0.3739 - top-5-accuracy: 0.6937 - val_loss: 2.3716 - val_accuracy: 0.3958 - val_top-5-accuracy: 0.6874\n",
      "Epoch 33/100\n",
      "176/176 [==============================] - 22s 125ms/step - loss: 2.3756 - accuracy: 0.3793 - top-5-accuracy: 0.6984 - val_loss: 2.3561 - val_accuracy: 0.4010 - val_top-5-accuracy: 0.6912\n",
      "Epoch 34/100\n",
      "176/176 [==============================] - 22s 125ms/step - loss: 2.3585 - accuracy: 0.3793 - top-5-accuracy: 0.7047 - val_loss: 2.3445 - val_accuracy: 0.4062 - val_top-5-accuracy: 0.6962\n",
      "Epoch 35/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 2.3539 - accuracy: 0.3816 - top-5-accuracy: 0.7057 - val_loss: 2.3386 - val_accuracy: 0.4044 - val_top-5-accuracy: 0.6930\n",
      "Epoch 36/100\n",
      "176/176 [==============================] - 22s 125ms/step - loss: 2.3394 - accuracy: 0.3875 - top-5-accuracy: 0.7067 - val_loss: 2.3479 - val_accuracy: 0.4074 - val_top-5-accuracy: 0.6910\n",
      "Epoch 37/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 2.3241 - accuracy: 0.3904 - top-5-accuracy: 0.7092 - val_loss: 2.3591 - val_accuracy: 0.4016 - val_top-5-accuracy: 0.6964\n",
      "Epoch 38/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 2.3124 - accuracy: 0.3915 - top-5-accuracy: 0.7122 - val_loss: 2.3324 - val_accuracy: 0.4044 - val_top-5-accuracy: 0.6968\n",
      "Epoch 39/100\n",
      "176/176 [==============================] - 22s 125ms/step - loss: 2.3040 - accuracy: 0.3933 - top-5-accuracy: 0.7133 - val_loss: 2.3296 - val_accuracy: 0.4090 - val_top-5-accuracy: 0.6966\n",
      "Epoch 40/100\n",
      "176/176 [==============================] - 21s 122ms/step - loss: 2.2835 - accuracy: 0.3981 - top-5-accuracy: 0.7199 - val_loss: 2.3276 - val_accuracy: 0.4074 - val_top-5-accuracy: 0.6988\n",
      "Epoch 41/100\n",
      "176/176 [==============================] - 22s 125ms/step - loss: 2.2741 - accuracy: 0.4004 - top-5-accuracy: 0.7222 - val_loss: 2.3103 - val_accuracy: 0.4148 - val_top-5-accuracy: 0.7036\n",
      "Epoch 42/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 2.2661 - accuracy: 0.4012 - top-5-accuracy: 0.7223 - val_loss: 2.3060 - val_accuracy: 0.4112 - val_top-5-accuracy: 0.6990\n",
      "Epoch 43/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 2.2546 - accuracy: 0.4016 - top-5-accuracy: 0.7256 - val_loss: 2.3092 - val_accuracy: 0.4146 - val_top-5-accuracy: 0.7046\n",
      "Epoch 44/100\n",
      "176/176 [==============================] - 21s 122ms/step - loss: 2.2417 - accuracy: 0.4072 - top-5-accuracy: 0.7282 - val_loss: 2.3043 - val_accuracy: 0.4074 - val_top-5-accuracy: 0.6978\n",
      "Epoch 45/100\n",
      "176/176 [==============================] - 22s 124ms/step - loss: 2.2318 - accuracy: 0.4091 - top-5-accuracy: 0.7331 - val_loss: 2.2835 - val_accuracy: 0.4124 - val_top-5-accuracy: 0.7122\n",
      "Epoch 46/100\n",
      "176/176 [==============================] - 22s 125ms/step - loss: 2.2301 - accuracy: 0.4089 - top-5-accuracy: 0.7305 - val_loss: 2.2796 - val_accuracy: 0.4238 - val_top-5-accuracy: 0.7022\n",
      "Epoch 47/100\n",
      "176/176 [==============================] - 22s 124ms/step - loss: 2.2176 - accuracy: 0.4147 - top-5-accuracy: 0.7332 - val_loss: 2.2697 - val_accuracy: 0.4238 - val_top-5-accuracy: 0.7066\n",
      "Epoch 48/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 2.2101 - accuracy: 0.4134 - top-5-accuracy: 0.7364 - val_loss: 2.2610 - val_accuracy: 0.4212 - val_top-5-accuracy: 0.7102\n",
      "Epoch 49/100\n",
      "176/176 [==============================] - 22s 124ms/step - loss: 2.1836 - accuracy: 0.4172 - top-5-accuracy: 0.7429 - val_loss: 2.2721 - val_accuracy: 0.4214 - val_top-5-accuracy: 0.7098\n",
      "Epoch 50/100\n",
      "176/176 [==============================] - 21s 122ms/step - loss: 2.1841 - accuracy: 0.4198 - top-5-accuracy: 0.7398 - val_loss: 2.2670 - val_accuracy: 0.4202 - val_top-5-accuracy: 0.7058\n",
      "Epoch 51/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 2.1778 - accuracy: 0.4198 - top-5-accuracy: 0.7443 - val_loss: 2.2595 - val_accuracy: 0.4198 - val_top-5-accuracy: 0.7122\n",
      "Epoch 52/100\n",
      "176/176 [==============================] - 22s 125ms/step - loss: 2.1769 - accuracy: 0.4205 - top-5-accuracy: 0.7420 - val_loss: 2.2597 - val_accuracy: 0.4272 - val_top-5-accuracy: 0.7078\n",
      "Epoch 53/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 2.1585 - accuracy: 0.4242 - top-5-accuracy: 0.7454 - val_loss: 2.2679 - val_accuracy: 0.4194 - val_top-5-accuracy: 0.7130\n",
      "Epoch 54/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 2.1445 - accuracy: 0.4282 - top-5-accuracy: 0.7483 - val_loss: 2.2458 - val_accuracy: 0.4232 - val_top-5-accuracy: 0.7164\n",
      "Epoch 55/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 2.1469 - accuracy: 0.4277 - top-5-accuracy: 0.7497 - val_loss: 2.2619 - val_accuracy: 0.4162 - val_top-5-accuracy: 0.7114\n",
      "Epoch 56/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 2.1378 - accuracy: 0.4308 - top-5-accuracy: 0.7517 - val_loss: 2.2395 - val_accuracy: 0.4258 - val_top-5-accuracy: 0.7156\n",
      "Epoch 57/100\n",
      "176/176 [==============================] - 21s 121ms/step - loss: 2.1314 - accuracy: 0.4293 - top-5-accuracy: 0.7516 - val_loss: 2.2447 - val_accuracy: 0.4204 - val_top-5-accuracy: 0.7126\n",
      "Epoch 58/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 2.1275 - accuracy: 0.4300 - top-5-accuracy: 0.7512 - val_loss: 2.2507 - val_accuracy: 0.4206 - val_top-5-accuracy: 0.7120\n",
      "Epoch 59/100\n",
      "176/176 [==============================] - 21s 122ms/step - loss: 2.1107 - accuracy: 0.4334 - top-5-accuracy: 0.7564 - val_loss: 2.2379 - val_accuracy: 0.4264 - val_top-5-accuracy: 0.7142\n",
      "Epoch 60/100\n",
      "176/176 [==============================] - 22s 125ms/step - loss: 2.1068 - accuracy: 0.4340 - top-5-accuracy: 0.7563 - val_loss: 2.2432 - val_accuracy: 0.4268 - val_top-5-accuracy: 0.7082\n",
      "Epoch 61/100\n",
      "176/176 [==============================] - 22s 125ms/step - loss: 2.1005 - accuracy: 0.4370 - top-5-accuracy: 0.7580 - val_loss: 2.2209 - val_accuracy: 0.4284 - val_top-5-accuracy: 0.7166\n",
      "Epoch 62/100\n",
      "176/176 [==============================] - 22s 124ms/step - loss: 2.0956 - accuracy: 0.4385 - top-5-accuracy: 0.7602 - val_loss: 2.2484 - val_accuracy: 0.4200 - val_top-5-accuracy: 0.7158\n",
      "Epoch 63/100\n",
      "176/176 [==============================] - 22s 125ms/step - loss: 2.0802 - accuracy: 0.4389 - top-5-accuracy: 0.7614 - val_loss: 2.2159 - val_accuracy: 0.4340 - val_top-5-accuracy: 0.7176\n",
      "Epoch 64/100\n",
      "176/176 [==============================] - 22s 124ms/step - loss: 2.0843 - accuracy: 0.4379 - top-5-accuracy: 0.7611 - val_loss: 2.2043 - val_accuracy: 0.4328 - val_top-5-accuracy: 0.7234\n",
      "Epoch 65/100\n",
      "176/176 [==============================] - 22s 125ms/step - loss: 2.0721 - accuracy: 0.4432 - top-5-accuracy: 0.7633 - val_loss: 2.1934 - val_accuracy: 0.4444 - val_top-5-accuracy: 0.7236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 2.0734 - accuracy: 0.4432 - top-5-accuracy: 0.7651 - val_loss: 2.2065 - val_accuracy: 0.4310 - val_top-5-accuracy: 0.7196\n",
      "Epoch 67/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 2.0585 - accuracy: 0.4468 - top-5-accuracy: 0.7681 - val_loss: 2.2022 - val_accuracy: 0.4402 - val_top-5-accuracy: 0.7212\n",
      "Epoch 68/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 2.0536 - accuracy: 0.4444 - top-5-accuracy: 0.7679 - val_loss: 2.2121 - val_accuracy: 0.4382 - val_top-5-accuracy: 0.7198\n",
      "Epoch 69/100\n",
      "176/176 [==============================] - 22s 122ms/step - loss: 2.0505 - accuracy: 0.4476 - top-5-accuracy: 0.7674 - val_loss: 2.2032 - val_accuracy: 0.4318 - val_top-5-accuracy: 0.7194\n",
      "Epoch 70/100\n",
      "176/176 [==============================] - 21s 122ms/step - loss: 2.0381 - accuracy: 0.4498 - top-5-accuracy: 0.7696 - val_loss: 2.2062 - val_accuracy: 0.4310 - val_top-5-accuracy: 0.7226\n",
      "Epoch 71/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 2.0442 - accuracy: 0.4476 - top-5-accuracy: 0.7681 - val_loss: 2.1866 - val_accuracy: 0.4336 - val_top-5-accuracy: 0.7264\n",
      "Epoch 72/100\n",
      "176/176 [==============================] - 21s 121ms/step - loss: 2.0342 - accuracy: 0.4491 - top-5-accuracy: 0.7708 - val_loss: 2.1881 - val_accuracy: 0.4360 - val_top-5-accuracy: 0.7286\n",
      "Epoch 73/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 2.0261 - accuracy: 0.4532 - top-5-accuracy: 0.7767 - val_loss: 2.1891 - val_accuracy: 0.4422 - val_top-5-accuracy: 0.7248\n",
      "Epoch 74/100\n",
      "176/176 [==============================] - 21s 122ms/step - loss: 2.0230 - accuracy: 0.4512 - top-5-accuracy: 0.7746 - val_loss: 2.1976 - val_accuracy: 0.4380 - val_top-5-accuracy: 0.7242\n",
      "Epoch 75/100\n",
      "176/176 [==============================] - 22s 124ms/step - loss: 2.0175 - accuracy: 0.4549 - top-5-accuracy: 0.7720 - val_loss: 2.2023 - val_accuracy: 0.4328 - val_top-5-accuracy: 0.7246\n",
      "Epoch 76/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 2.0097 - accuracy: 0.4578 - top-5-accuracy: 0.7770 - val_loss: 2.1843 - val_accuracy: 0.4406 - val_top-5-accuracy: 0.7284\n",
      "Epoch 77/100\n",
      "176/176 [==============================] - 22s 124ms/step - loss: 2.0004 - accuracy: 0.4571 - top-5-accuracy: 0.7792 - val_loss: 2.1710 - val_accuracy: 0.4404 - val_top-5-accuracy: 0.7318\n",
      "Epoch 78/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 1.9974 - accuracy: 0.4618 - top-5-accuracy: 0.7778 - val_loss: 2.1904 - val_accuracy: 0.4378 - val_top-5-accuracy: 0.7252\n",
      "Epoch 79/100\n",
      "176/176 [==============================] - 22s 124ms/step - loss: 1.9998 - accuracy: 0.4573 - top-5-accuracy: 0.7789 - val_loss: 2.1968 - val_accuracy: 0.4372 - val_top-5-accuracy: 0.7276\n",
      "Epoch 80/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 1.9912 - accuracy: 0.4602 - top-5-accuracy: 0.7823 - val_loss: 2.1714 - val_accuracy: 0.4424 - val_top-5-accuracy: 0.7298\n",
      "Epoch 81/100\n",
      "176/176 [==============================] - 22s 124ms/step - loss: 1.9877 - accuracy: 0.4593 - top-5-accuracy: 0.7825 - val_loss: 2.1721 - val_accuracy: 0.4430 - val_top-5-accuracy: 0.7330\n",
      "Epoch 82/100\n",
      "176/176 [==============================] - 22s 125ms/step - loss: 1.9814 - accuracy: 0.4603 - top-5-accuracy: 0.7829 - val_loss: 2.1647 - val_accuracy: 0.4458 - val_top-5-accuracy: 0.7326\n",
      "Epoch 83/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 1.9802 - accuracy: 0.4614 - top-5-accuracy: 0.7848 - val_loss: 2.1572 - val_accuracy: 0.4386 - val_top-5-accuracy: 0.7356\n",
      "Epoch 84/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 1.9738 - accuracy: 0.4624 - top-5-accuracy: 0.7846 - val_loss: 2.1815 - val_accuracy: 0.4338 - val_top-5-accuracy: 0.7328\n",
      "Epoch 85/100\n",
      "176/176 [==============================] - 22s 122ms/step - loss: 1.9695 - accuracy: 0.4662 - top-5-accuracy: 0.7853 - val_loss: 2.1733 - val_accuracy: 0.4398 - val_top-5-accuracy: 0.7296\n",
      "Epoch 86/100\n",
      "176/176 [==============================] - 22s 122ms/step - loss: 1.9601 - accuracy: 0.4640 - top-5-accuracy: 0.7855 - val_loss: 2.1846 - val_accuracy: 0.4384 - val_top-5-accuracy: 0.7258\n",
      "Epoch 87/100\n",
      "176/176 [==============================] - 21s 121ms/step - loss: 1.9523 - accuracy: 0.4680 - top-5-accuracy: 0.7880 - val_loss: 2.1710 - val_accuracy: 0.4426 - val_top-5-accuracy: 0.7306\n",
      "Epoch 88/100\n",
      "176/176 [==============================] - 22s 125ms/step - loss: 1.9502 - accuracy: 0.4660 - top-5-accuracy: 0.7897 - val_loss: 2.1714 - val_accuracy: 0.4474 - val_top-5-accuracy: 0.7304\n",
      "Epoch 89/100\n",
      "176/176 [==============================] - 21s 121ms/step - loss: 1.9430 - accuracy: 0.4680 - top-5-accuracy: 0.7898 - val_loss: 2.1609 - val_accuracy: 0.4454 - val_top-5-accuracy: 0.7282\n",
      "Epoch 90/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 1.9546 - accuracy: 0.4667 - top-5-accuracy: 0.7871 - val_loss: 2.1587 - val_accuracy: 0.4432 - val_top-5-accuracy: 0.7384\n",
      "Epoch 91/100\n",
      "176/176 [==============================] - 21s 122ms/step - loss: 1.9359 - accuracy: 0.4724 - top-5-accuracy: 0.7905 - val_loss: 2.1603 - val_accuracy: 0.4450 - val_top-5-accuracy: 0.7422\n",
      "Epoch 92/100\n",
      "176/176 [==============================] - 22s 125ms/step - loss: 1.9349 - accuracy: 0.4697 - top-5-accuracy: 0.7920 - val_loss: 2.1603 - val_accuracy: 0.4458 - val_top-5-accuracy: 0.7328\n",
      "Epoch 93/100\n",
      "176/176 [==============================] - 21s 122ms/step - loss: 1.9193 - accuracy: 0.4733 - top-5-accuracy: 0.7970 - val_loss: 2.1577 - val_accuracy: 0.4432 - val_top-5-accuracy: 0.7364\n",
      "Epoch 94/100\n",
      "176/176 [==============================] - 22s 124ms/step - loss: 1.9199 - accuracy: 0.4756 - top-5-accuracy: 0.7947 - val_loss: 2.1472 - val_accuracy: 0.4470 - val_top-5-accuracy: 0.7360\n",
      "Epoch 95/100\n",
      "176/176 [==============================] - 22s 125ms/step - loss: 1.9204 - accuracy: 0.4759 - top-5-accuracy: 0.7943 - val_loss: 2.1521 - val_accuracy: 0.4478 - val_top-5-accuracy: 0.7384\n",
      "Epoch 96/100\n",
      "176/176 [==============================] - 22s 126ms/step - loss: 1.9182 - accuracy: 0.4759 - top-5-accuracy: 0.7953 - val_loss: 2.1316 - val_accuracy: 0.4514 - val_top-5-accuracy: 0.7366\n",
      "Epoch 97/100\n",
      "176/176 [==============================] - 21s 122ms/step - loss: 1.9212 - accuracy: 0.4779 - top-5-accuracy: 0.7966 - val_loss: 2.1456 - val_accuracy: 0.4452 - val_top-5-accuracy: 0.7356\n",
      "Epoch 98/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 1.9119 - accuracy: 0.4778 - top-5-accuracy: 0.7968 - val_loss: 2.1362 - val_accuracy: 0.4482 - val_top-5-accuracy: 0.7428\n",
      "Epoch 99/100\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 1.8997 - accuracy: 0.4816 - top-5-accuracy: 0.7979 - val_loss: 2.1285 - val_accuracy: 0.4462 - val_top-5-accuracy: 0.7444\n",
      "Epoch 100/100\n",
      "176/176 [==============================] - 22s 122ms/step - loss: 1.8942 - accuracy: 0.4809 - top-5-accuracy: 0.8008 - val_loss: 2.1344 - val_accuracy: 0.4500 - val_top-5-accuracy: 0.7426\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 2.0894 - accuracy: 0.4631 - top-5-accuracy: 0.7483\n",
      "Test accuracy: 46.31%\n",
      "Test top 5 accuracy: 74.83%\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "def run_experiment(model, z):\n",
    "    optimizer = tfa.optimizers.AdamW(\n",
    "        learning_rate=learning_rate, weight_decay=weight_decay\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=[\n",
    "            keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\"),\n",
    "            keras.metrics.SparseTopKCategoricalAccuracy(5, name=\"top-5-accuracy\"),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    checkpoint_filepath = \"/tmp/checkpoint\"\n",
    "    checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "        checkpoint_filepath,\n",
    "        monitor=\"val_accuracy\",\n",
    "        save_best_only=True,\n",
    "        save_weights_only=True,\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "        x=x_train,\n",
    "        y=y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=num_epochs,\n",
    "        validation_split=0.1,\n",
    "        callbacks=[checkpoint_callback],\n",
    "    )\n",
    "\n",
    "    model.load_weights(checkpoint_filepath)\n",
    "    _, accuracy, top_5_accuracy = model.evaluate(x_test, y_test)\n",
    "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
    "    print(f\"Test top 5 accuracy: {round(top_5_accuracy * 100, 2)}%\")\n",
    "    results{z}=(accuracy,top_5_accuracy)\n",
    "    return history\n",
    "\n",
    "for z in [4,6,8,10]:\n",
    "    print(f'------------------------\\n{z} layers\\n------------------')\n",
    "    tranformer_layers=z\n",
    "    vit_classifier = create_vit_classifier()\n",
    "    history = run_experiment(vit_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keras.utils.plot_model(vit_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 layers: test acc=46.56, test top5acc=46.56\n",
      "6 layers: test acc=46.42, test top5acc=46.42\n",
      "8 layers: test acc=46.65, test top5acc=46.65\n",
      "10 layers: test acc=46.31, test top5acc=46.31\n"
     ]
    }
   ],
   "source": [
    "for i in results:\n",
    "    print(f\"{i} layers: test acc={results[i][0]}, test top5acc={results[i][0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [20]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mload_weights(checkpoint_filepath)\n\u001b[1;32m      2\u001b[0m _, accuracy, top_5_accuracy \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(x_test, y_test)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mround\u001b[39m(accuracy \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m2\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "55c4ba169dd9b3ee397b3ef1f764a83578d9541389355fe155bcac7e801a5a5f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
